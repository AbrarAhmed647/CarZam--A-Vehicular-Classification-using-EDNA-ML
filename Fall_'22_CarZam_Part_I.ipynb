{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbrarAhmed647/CarZam--A-Vehicular-Classification-using-EDNA-ML/blob/main/Fall_'22_CarZam_Part_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading"
      ],
      "metadata": {
        "id": "IIvMmyor1zCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X2MfjyJ2rHy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d898675-0909-4179-c232-3a29d9a2ab71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 03:21:29--  https://www.dropbox.com/s/pha9yzdfkmzoqob/original_tool_images.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/pha9yzdfkmzoqob/original_tool_images.zip [following]\n",
            "--2022-12-02 03:21:29--  https://www.dropbox.com/s/raw/pha9yzdfkmzoqob/original_tool_images.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc077de2f19b70b9e4f691a669a7.dl.dropboxusercontent.com/cd/0/inline/Bx3kUNjZwv-sxFEXEjBTjMThUK4zXSeomdThkyQyx7_CSjgRQbXlp6UTgswbTtJA5TFJVVpTgpWQa5CXSDtlKYxsVLG90eNqQJqEsZUpv9nT-0dRO_NI4Pnttsmk5WVVjVRAVNyIrK_W5TnImMh1GoDws90MJVUXPQKqKnNQvuym9A/file# [following]\n",
            "--2022-12-02 03:21:30--  https://uc077de2f19b70b9e4f691a669a7.dl.dropboxusercontent.com/cd/0/inline/Bx3kUNjZwv-sxFEXEjBTjMThUK4zXSeomdThkyQyx7_CSjgRQbXlp6UTgswbTtJA5TFJVVpTgpWQa5CXSDtlKYxsVLG90eNqQJqEsZUpv9nT-0dRO_NI4Pnttsmk5WVVjVRAVNyIrK_W5TnImMh1GoDws90MJVUXPQKqKnNQvuym9A/file\n",
            "Resolving uc077de2f19b70b9e4f691a669a7.dl.dropboxusercontent.com (uc077de2f19b70b9e4f691a669a7.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to uc077de2f19b70b9e4f691a669a7.dl.dropboxusercontent.com (uc077de2f19b70b9e4f691a669a7.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Bx3pFD0uTQMPCHbWZCZv1z1rRUXxS8IkITRJn5UoTbJdwAMDPMvN5Bj_T5iVbMKEVKx5RS7Z8-tlXcB3cTyTaH5AFYCIzKhCjM1MgY6GATwtsJKvEgNhhy6BJfJpj1ZrOX1cPGp5Ss3BDbP3u8XUkL8ZbkJ9l3nRXFWC3MlzU5nnwrSg-fXNYg51hno36LOpUCBuNJ_YJ8qfcFEih3mDhn_fPI4YoSWOW3xlvEptyPoQC3irhkKijq4yfmpNYh3C1OznKP-n4ET63oUGTjSYKanUWB1XLLFwuhT8CndE1_cfw6QzFOGfGsavTQHYAFml-zFBfwOcya7KQO0llmrmKLiUACFM8YBAnI57bATN69o0B5Tgzn9TTqsGq8DmuYg7T2YhGYkCuPVWrGW5MzUmS5usYLv_4iat5r9JSawQUIJ0YQ/file [following]\n",
            "--2022-12-02 03:21:30--  https://uc077de2f19b70b9e4f691a669a7.dl.dropboxusercontent.com/cd/0/inline2/Bx3pFD0uTQMPCHbWZCZv1z1rRUXxS8IkITRJn5UoTbJdwAMDPMvN5Bj_T5iVbMKEVKx5RS7Z8-tlXcB3cTyTaH5AFYCIzKhCjM1MgY6GATwtsJKvEgNhhy6BJfJpj1ZrOX1cPGp5Ss3BDbP3u8XUkL8ZbkJ9l3nRXFWC3MlzU5nnwrSg-fXNYg51hno36LOpUCBuNJ_YJ8qfcFEih3mDhn_fPI4YoSWOW3xlvEptyPoQC3irhkKijq4yfmpNYh3C1OznKP-n4ET63oUGTjSYKanUWB1XLLFwuhT8CndE1_cfw6QzFOGfGsavTQHYAFml-zFBfwOcya7KQO0llmrmKLiUACFM8YBAnI57bATN69o0B5Tgzn9TTqsGq8DmuYg7T2YhGYkCuPVWrGW5MzUmS5usYLv_4iat5r9JSawQUIJ0YQ/file\n",
            "Reusing existing connection to uc077de2f19b70b9e4f691a669a7.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87282712 (83M) [application/zip]\n",
            "Saving to: ‘original_tool_image.zip’\n",
            "\n",
            "original_tool_image 100%[===================>]  83.24M   101MB/s    in 0.8s    \n",
            "\n",
            "2022-12-02 03:21:32 (101 MB/s) - ‘original_tool_image.zip’ saved [87282712/87282712]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists('./original_tool_image.zip'):\n",
        "  ! wget -O original_tool_image.zip https://www.dropbox.com/s/pha9yzdfkmzoqob/original_tool_images.zip?dl=0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "_mtMC8V8r43T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqJoyEW1f_a1"
      },
      "source": [
        "## Git Clone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oisq4kE8IMHi"
      },
      "source": [
        "### From Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bJfycQTLVkEj"
      },
      "outputs": [],
      "source": [
        "! rm -rf -- GLAMOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "goBMKUmagBIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21bdadb0-42ff-432b-8998-6b91326910ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GLAMOR'...\n",
            "remote: Enumerating objects: 8407, done.\u001b[K\n",
            "remote: Counting objects: 100% (310/310), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 8407 (delta 187), reused 214 (delta 106), pack-reused 8097\u001b[K\n",
            "Receiving objects: 100% (8407/8407), 2.21 MiB | 13.64 MiB/s, done.\n",
            "Resolving deltas: 100% (5580/5580), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone -b master https://github.com/asuprem/GLAMOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T80AC-kx4v4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5caf2401-aafd-428a-9379-5eb44fe8f0be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/GLAMOR\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (1.0.2)\n",
            "Requirement already satisfied: torch>=1.10.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (1.12.1+cu113)\n",
            "Collecting torchinfo>=1.6.5\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: torchvision>=0.11.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (0.13.1+cu113)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (7.1.2)\n",
            "Requirement already satisfied: tqdm>=4.63.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (4.64.1)\n",
            "Collecting sentencepiece>=0.1.96\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (2.4.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (6.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.*->ednaml==0.1.5) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.11.*->ednaml==0.1.5) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (1.24.3)\n",
            "Installing collected packages: torchinfo, sentencepiece, ednaml\n",
            "  Running setup.py develop for ednaml\n",
            "Successfully installed ednaml-0.1.5 sentencepiece-0.1.97 torchinfo-1.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -e GLAMOR/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5j3WfN0fpIT"
      },
      "source": [
        "###  From PyPi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f7dkOhZi08dU"
      },
      "outputs": [],
      "source": [
        "#! python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FwqgjiZ331ik"
      },
      "outputs": [],
      "source": [
        "#! pip3 install --pre ednaml==0.1.4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restart Notebook to Finish EdnaML Installation"
      ],
      "metadata": {
        "id": "84c7mTxBr7Sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up"
      ],
      "metadata": {
        "id": "j6-WuaR3sX5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "rW5_Xxhvr7IT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "#from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "zXxdpMEtr7GG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "78005836-7861-4234-accc-3ddb03e28253"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.1+cu113'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definitions: Crawler"
      ],
      "metadata": {
        "id": "9PfHu-KZsQ9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we define our custom model class\n",
        "from ednaml.crawlers import Crawler\n",
        "from zipfile import ZipFile # might be useful in unzipping!\n",
        "\n",
        "class CarZamCrawler(Crawler):\n",
        "  def __init__(self, logger, file_name = \"original_tool_images.zip\", **kwargs): # Add your own arguments if needed!\n",
        "    self.classes = {}\n",
        "    self.metadata = {}\n",
        "    self.metadata[\"train\"] = {}\n",
        "    self.metadata[\"test\"] = {}\n",
        "    self.metadata[\"val\"] = {}\n",
        "    self.metadata[\"train\"][\"crawl\"] = []  # <------ THIS NEEDS TO BE POPULATED\n",
        "    self.metadata[\"test\"][\"crawl\"] = []   # <------ THIS NEEDS TO BE POPULATED\n",
        "    self.metadata[\"val\"][\"crawl\"] = []    # <------ THIS NEEDS TO BE POPULATED\n",
        "\n",
        "    # YOUR CODE HERE ------ POPULATE self.classes and self.metadata's empty lists ---\n",
        "    from zipfile import ZipFile\n",
        "    file_name = \"original_tool_image.zip\"\n",
        "    fdest= \"unzipped\"\n",
        "    if not os.path.exists(fdest):\n",
        "      with ZipFile(file_name, 'r') as zip: \n",
        "          # extract all files to another directory\n",
        "          zip.extractall(fdest)\n",
        "    fllist = glob.glob(os.path.join(fdest, \"original_tool_images/*.jpg\"))\n",
        "    #tuple_prelim = [self.getinittuple(item) for item in fllist]\n",
        "    temp=[]\n",
        "    #ans=[]\n",
        "    tokeep = [\"Convertible\", \"Coupe\", \"Crossover\", \"Diesel\", \"Hybrid\", \"Sedan\", \"SUV\", \"Wagon\",\"SportsCar\", \"Truck\", \"Van\", ]\n",
        "    tuple_expanded=[]\n",
        "    for item in fllist:\n",
        "      tuple_prelim=os.path.splitext(os.path.basename(item))[0].split(\" \"), item\n",
        "      #print(tuple_prelim)\n",
        "      if(len(tuple_prelim[0])==5):\n",
        "        temp.append(tuple_prelim[1]) #appending path\n",
        "        for i in tuple_prelim[0]:  #appending type,color,year,make,model\n",
        "            if(i==\"CoupeBlack\"):\n",
        "             temp.append(\"Coupe\")\n",
        "             temp.append(\"Black\")\n",
        "             temp.append(tuple_prelim[1:])\n",
        "            else:\n",
        "              temp.append(i)\n",
        "        \n",
        "        my_tuple=tuple(temp)        #list to Tuple\n",
        "        tuple_expanded.append(my_tuple)   \n",
        "        temp=[]\n",
        "      elif(len(tuple_prelim[0])==6):\n",
        "        temp.append(tuple_prelim[1])\n",
        "        if(tuple_prelim[0][0]) in tokeep:\n",
        "          for i in tuple_prelim[0][:4]:\n",
        "            temp.append(i)\n",
        "          temp.append(tuple_prelim[0][4]+tuple_prelim[0][5])\n",
        "\n",
        "          my_tuple=tuple(temp)\n",
        "          tuple_expanded.append(my_tuple)\n",
        "          temp=[]\n",
        "        else:\n",
        "          temp.append(tuple_prelim[0][0]+tuple_prelim[0][1])\n",
        "          for i in tuple_prelim[0][2:]:\n",
        "            temp.append(i)\n",
        "          #temp.append(tuple_prelim[1])\n",
        "          my_tuple=tuple(temp)\n",
        "          tuple_expanded.append(my_tuple)\n",
        "          temp=[]\n",
        "  #print(ans)\n",
        "      elif(len(tuple_prelim[0])==7):\n",
        "        temp.append(tuple_prelim[1])\n",
        "        if tuple_prelim[0][0] in tokeep:\n",
        "          for i in tuple_prelim[0][:4]:\n",
        "            temp.append(i)\n",
        "          temp.append(tuple_prelim[0][4:])\n",
        "\n",
        "          my_tuple=tuple(temp)\n",
        "          tuple_expanded.append(my_tuple)\n",
        "          temp=[]\n",
        "        else:\n",
        "          temp.append(tuple_prelim[0][0]+tuple_prelim[0][1])\n",
        "          for i in tuple_prelim[0][2:5]:\n",
        "            temp.append(i)\n",
        "          temp.append(tuple_prelim[0][5]+tuple_prelim[0][6])\n",
        "        \n",
        "          my_tuple=tuple(temp)\n",
        "          tuple_expanded.append(my_tuple)\n",
        "          temp=[]\n",
        "    #print(\"Tuple_expanded:\")\n",
        "    #print(tuple_expanded[0])\n",
        "    import random\n",
        "    random.seed(3456)\n",
        "    random.shuffle(tuple_expanded)\n",
        "\n",
        "    splits = 0.8\n",
        "    train_sets = int(len(tuple_expanded)*0.8)\n",
        "    val_sets = int(len(tuple_expanded)*0.1)\n",
        "\n",
        "    \n",
        "\n",
        "    # structure:  (path, type, color, year, make)\n",
        "    # idx           0     1     2     3     4\n",
        "    print(\"Outliers\\n\")\n",
        "    for item in tuple_expanded:\n",
        "      if(item[1]=='CoupeBlack'):\n",
        "        print(item)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    types = list(set([item[1] for item in tuple_expanded]))\n",
        "    print(\"types:\",types)\n",
        "    colors = list(set([item[2] for item in tuple_expanded]))\n",
        "    years = list(set([item[3] for item in tuple_expanded]))\n",
        "    makes = list(set([item[4] for item in tuple_expanded]))\n",
        "\n",
        "    self.classes[\"vtype\"] = len(types)\n",
        "    self.classes[\"color\"] = len(colors)\n",
        "    self.classes[\"year\"] = len(years)\n",
        "    self.classes[\"make\"] = len(makes)\n",
        "\n",
        "    self.type_lookup = {item:idx for idx,item in enumerate(types)}\n",
        "    self.color_lookup = {item:idx for idx,item in enumerate(colors)}\n",
        "    self.year_lookup = {item:idx for idx,item in enumerate(years)}\n",
        "    self.make_lookup = {item:idx for idx,item in enumerate(makes)}\n",
        "\n",
        "    tuple_expanded = [(item[0], self.type_lookup[item[1]], self.color_lookup[item[2]], self.year_lookup[item[3]], self.make_lookup[item[4]]) for item in tuple_expanded]\n",
        "    print(\"Tuple_expanded\\n\")\n",
        "    print(tuple_expanded[:5])\n",
        "\n",
        "    #split the datasets\n",
        "    self.metadata[\"train\"][\"crawl\"] = tuple_expanded[:train_sets]\n",
        "    self.metadata[\"val\"][\"crawl\"] = tuple_expanded[train_sets:val_sets]\n",
        "    self.metadata[\"test\"][\"crawl\"] = tuple_expanded[train_sets+val_sets:]\n",
        "\n",
        "\n",
        "    # -------------------------------------------------------------------------------\n",
        "\n",
        "    self.metadata[\"train\"][\"classes\"] = self.classes\n",
        "    self.metadata[\"test\"][\"classes\"] = self.classes\n",
        "    self.metadata[\"val\"][\"classes\"] = self.classes\n",
        "\n",
        "  def getinittuple(self, item):\n",
        "    return (os.path.splitext(os.path.basename(item))[0].split(\" \"), item)\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "-2z_FeuUsSr6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Crawler"
      ],
      "metadata": {
        "id": "_GzkE8ymuUj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"logger\" : None,\n",
        "    \"file_name\" : \"original_tool_images.zip\",\n",
        "    # add any other kwargs here...\n",
        "}"
      ],
      "metadata": {
        "id": "x0GIxddZuarz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crawler = CarZamCrawler(**kwargs)"
      ],
      "metadata": {
        "id": "BIGL8tGzuWs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598fe431-9681-4c21-f2e0-c782f8a6dcb7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers\n",
            "\n",
            "types: ['ElectricVehicle', 'Wagon', 'Coupe', 'SUV', 'Van', 'PickupTruck', 'Sedan', 'Hybrid', 'LuxuryVehicle', 'Convertible', 'Diesel', 'SportsCar', 'Crossover']\n",
            "Tuple_expanded\n",
            "\n",
            "[('unzipped/original_tool_images/Hybrid Silver 2021 Toyota Avalon Hybrid.jpg', 7, 2, 0, 7), ('unzipped/original_tool_images/Crossover Black 2018 Jeep Compass.jpg', 12, 3, 5, 27), ('unzipped/original_tool_images/Sedan Gray 2017 Honda Fit.jpg', 6, 0, 8, 10), ('unzipped/original_tool_images/Pickup Truck Tan 2017 Toyota Tacoma.jpg', 5, 7, 8, 7), ('unzipped/original_tool_images/Luxury Vehicle Gold 2015 Cadillac CTS.jpg', 8, 11, 1, 18)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crawler.classes # You should get the classes here"
      ],
      "metadata": {
        "id": "bf3QLBgWuouh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19d13424-14e9-4150-9d37-998ff50ecfce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vtype': 13, 'color': 13, 'year': 14, 'make': 36}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crawler.metadata[\"train\"][\"crawl\"][:5]  # You should get the list of tuples here"
      ],
      "metadata": {
        "id": "Aud7dfjGunhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826ec410-b7de-4f07-da52-9347abffb64f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('unzipped/original_tool_images/Hybrid Silver 2021 Toyota Avalon Hybrid.jpg',\n",
              "  7,\n",
              "  2,\n",
              "  0,\n",
              "  7),\n",
              " ('unzipped/original_tool_images/Crossover Black 2018 Jeep Compass.jpg',\n",
              "  12,\n",
              "  3,\n",
              "  5,\n",
              "  27),\n",
              " ('unzipped/original_tool_images/Sedan Gray 2017 Honda Fit.jpg', 6, 0, 8, 10),\n",
              " ('unzipped/original_tool_images/Pickup Truck Tan 2017 Toyota Tacoma.jpg',\n",
              "  5,\n",
              "  7,\n",
              "  8,\n",
              "  7),\n",
              " ('unzipped/original_tool_images/Luxury Vehicle Gold 2015 Cadillac CTS.jpg',\n",
              "  8,\n",
              "  11,\n",
              "  1,\n",
              "  18)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics"
      ],
      "metadata": {
        "id": "l6_TufwByRmh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1wBxjlp036h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dO9dJ0R-1Io0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code to collect info on # makes, models, year, type"
      ],
      "metadata": {
        "id": "7yRF6u3MySi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 Single classification (Vehicle Type)"
      ],
      "metadata": {
        "id": "1FfnWjLr2YnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = \"vtype\"  # Make sure to change this to whatever name you used for make in your `original_tool_images` crawler\n",
        "class_idx = 1         # Make sure to change this to whetever index `type` is in your Crawler's tuple!\n",
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "3TklNIgR2a9F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDaa1wOf24HB",
        "outputId": "9cd1fd9c-2e79-4276-99a8-b1e5a6f9696d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = \"./GLAMOR/profiles/CarZam/base_config.yml\", config_inject=[\n",
        "    (\"SAVE.MODEL_QUALIFIER\", class_name)\n",
        "])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtj3SqdS24Js",
        "outputId": "6e264aca-085e-4bf8-9236-c465bfde0c1c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, vtype\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQXyMY8s24NH",
        "outputId": "349b375a-7f3a-4324-eadc-02e5956bed12"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:26:57 ****************************************\n",
            "03:26:57 \n",
            "03:26:57 \n",
            "03:26:57 Using the following configuration:\n",
            "03:26:57 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx: 1\n",
            "      classificationclass: vtype\n",
            "      pathidx: 0\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: ClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: ''\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: out1\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: classification_model_builder\n",
            "  MODEL_ARCH: ClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS: {}\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: singleclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: vtype\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "03:26:57 \n",
            "03:26:57 \n",
            "03:26:57 ****************************************\n",
            "03:26:57 Model weights file resnet18-5c106cde.pth does not exist. Downloading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46827520/46827520 bytes [████████████████████████████████████████████████████████████████████████████████████████████████████]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:26:57 No previous stop detected. Will start from epoch 0\n",
            "03:26:57 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "03:26:57 Reading data with DataReader DataReader\n",
            "03:26:57 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "03:26:57 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "03:26:57 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "03:26:57 Updating GENERATOR to queued class ClassificationGenerator\n",
            "03:26:57 Updating CRAWLER to CarZamCrawler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Download of resnet18-5c106cde.pth to https://download.pytorch.org/models/resnet18-5c106cde.pth completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:26:57 Generated training data generator with 1575 training data points\n",
            "03:26:57 Running classification model with classes: {'vtype': {'classes': 13}}\n",
            "03:26:57 Generated test data/query generator\n",
            "03:26:57 Loaded classification_model_builder from ednaml.models to build model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers\n",
            "\n",
            "types: ['ElectricVehicle', 'Wagon', 'Coupe', 'SUV', 'Van', 'PickupTruck', 'Sedan', 'Hybrid', 'LuxuryVehicle', 'Convertible', 'Diesel', 'SportsCar', 'Crossover']\n",
            "Tuple_expanded\n",
            "\n",
            "[('unzipped/original_tool_images/Hybrid Silver 2021 Toyota Avalon Hybrid.jpg', 7, 2, 0, 7), ('unzipped/original_tool_images/Crossover Black 2018 Jeep Compass.jpg', 12, 3, 5, 27), ('unzipped/original_tool_images/Sedan Gray 2017 Honda Fit.jpg', 6, 0, 8, 10), ('unzipped/original_tool_images/Pickup Truck Tan 2017 Toyota Tacoma.jpg', 5, 7, 8, 7), ('unzipped/original_tool_images/Luxury Vehicle Gold 2015 Cadillac CTS.jpg', 8, 11, 1, 18)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:26:58 Finished instantiating model with ClassificationResnet architecture\n",
            "03:26:58 Adding plugins after constructing model\n",
            "03:26:58 No saved model weights provided.\n",
            "03:27:02 Model Summary retured the following error:\n",
            "03:27:02 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "03:27:02 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "03:27:02 Built optimizer\n",
            "03:27:02 Built scheduler\n",
            "03:27:02 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "03:27:02 Built loss function\n",
            "03:27:02 Built loss optimizer\n",
            "03:27:02 Built loss scheduler\n",
            "03:27:02 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "03:27:02 Loaded ClassificationTrainer from ednaml.trainer to build Trainer\n",
            "03:27:02 Saving model metadata\n",
            "03:27:02 Backing up metadata\n",
            "03:27:02 Finished metadata backup\n",
            "03:27:02 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3DgrZI53vDA",
        "outputId": "8425ab24-b2fd-4d79-b165-e0981f9c1912"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:27:13 Starting training\n",
            "03:27:13 Logging to:\torigtoolimgs-v1-singleclass-vtype-logger.log\n",
            "03:27:13 Models will be saved to local directory:\torigtoolimgs-v1-singleclass-vtype\n",
            "03:27:13 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "03:27:13 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "03:27:13 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "03:27:13 Performing initial evaluation...\n",
            "03:27:20 Obtained features, validation in progress\n",
            "03:27:20 Accuracy: 14.141%\n",
            "03:27:20 Micro F-score: 0.141\n",
            "03:27:20 Weighted F-score: 0.063\n",
            "03:27:20 Starting training from 0\n",
            "03:27:21 Parameter Group `opt-1`: Starting epoch 0 with 50 steps and learning rate 1.00000E-05\n",
            "03:27:35 ********** Completed epoch 0 **********\n",
            "03:27:35 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:27:35 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:27:35 Parameter Group `opt-1`: Starting epoch 1 with 50 steps and learning rate 1.00000E-05\n",
            "03:27:36 Evaluating model at test-frequency\n",
            "03:27:38 Obtained features, validation in progress\n",
            "03:27:38 Accuracy: 28.788%\n",
            "03:27:38 Micro F-score: 0.288\n",
            "03:27:38 Weighted F-score: 0.287\n",
            "03:27:38 Saving model at save-frequency, at epoch 0, step 0\n",
            "03:27:38 Saving model, optimizer, and scheduler.\n",
            "03:27:50 ********** Completed epoch 1 **********\n",
            "03:27:50 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:27:50 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:27:51 Parameter Group `opt-1`: Starting epoch 2 with 50 steps and learning rate 1.00000E-05\n",
            "03:27:52 Evaluating model at test-frequency\n",
            "03:27:54 Obtained features, validation in progress\n",
            "03:27:54 Accuracy: 38.889%\n",
            "03:27:54 Micro F-score: 0.389\n",
            "03:27:54 Weighted F-score: 0.362\n",
            "03:27:54 Saving model at save-frequency, at epoch 1, step 0\n",
            "03:27:54 Saving model, optimizer, and scheduler.\n",
            "03:28:06 ********** Completed epoch 2 **********\n",
            "03:28:06 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:28:06 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:28:06 Parameter Group `opt-1`: Starting epoch 3 with 50 steps and learning rate 1.00000E-05\n",
            "03:28:07 Evaluating model at test-frequency\n",
            "03:28:09 Obtained features, validation in progress\n",
            "03:28:09 Accuracy: 41.919%\n",
            "03:28:09 Micro F-score: 0.419\n",
            "03:28:09 Weighted F-score: 0.391\n",
            "03:28:09 Saving model at save-frequency, at epoch 2, step 0\n",
            "03:28:09 Saving model, optimizer, and scheduler.\n",
            "03:28:22 ********** Completed epoch 3 **********\n",
            "03:28:22 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:28:22 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:28:22 Parameter Group `opt-1`: Starting epoch 4 with 50 steps and learning rate 1.00000E-05\n",
            "03:28:23 Evaluating model at test-frequency\n",
            "03:28:26 Obtained features, validation in progress\n",
            "03:28:26 Accuracy: 40.404%\n",
            "03:28:26 Micro F-score: 0.404\n",
            "03:28:26 Weighted F-score: 0.360\n",
            "03:28:26 Saving model at save-frequency, at epoch 3, step 0\n",
            "03:28:26 Saving model, optimizer, and scheduler.\n",
            "03:28:37 ********** Completed epoch 4 **********\n",
            "03:28:37 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:28:37 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:28:38 Parameter Group `opt-1`: Starting epoch 5 with 50 steps and learning rate 1.00000E-05\n",
            "03:28:38 Evaluating model at test-frequency\n",
            "03:28:41 Obtained features, validation in progress\n",
            "03:28:41 Accuracy: 41.919%\n",
            "03:28:41 Micro F-score: 0.419\n",
            "03:28:41 Weighted F-score: 0.375\n",
            "03:28:41 Saving model at save-frequency, at epoch 4, step 0\n",
            "03:28:41 Saving model, optimizer, and scheduler.\n",
            "03:28:52 ********** Completed epoch 5 **********\n",
            "03:28:52 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:28:52 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:28:53 Parameter Group `opt-1`: Starting epoch 6 with 50 steps and learning rate 1.00000E-05\n",
            "03:28:54 Evaluating model at test-frequency\n",
            "03:28:56 Obtained features, validation in progress\n",
            "03:28:56 Accuracy: 38.384%\n",
            "03:28:56 Micro F-score: 0.384\n",
            "03:28:56 Weighted F-score: 0.326\n",
            "03:28:56 Saving model at save-frequency, at epoch 5, step 0\n",
            "03:28:56 Saving model, optimizer, and scheduler.\n",
            "03:29:08 ********** Completed epoch 6 **********\n",
            "03:29:08 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:29:08 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:29:09 Parameter Group `opt-1`: Starting epoch 7 with 50 steps and learning rate 1.00000E-05\n",
            "03:29:09 Evaluating model at test-frequency\n",
            "03:29:12 Obtained features, validation in progress\n",
            "03:29:12 Accuracy: 39.394%\n",
            "03:29:12 Micro F-score: 0.394\n",
            "03:29:12 Weighted F-score: 0.325\n",
            "03:29:12 Saving model at save-frequency, at epoch 6, step 0\n",
            "03:29:12 Saving model, optimizer, and scheduler.\n",
            "03:29:24 ********** Completed epoch 7 **********\n",
            "03:29:24 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:29:24 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:29:24 Parameter Group `opt-1`: Starting epoch 8 with 50 steps and learning rate 1.00000E-05\n",
            "03:29:25 Evaluating model at test-frequency\n",
            "03:29:28 Obtained features, validation in progress\n",
            "03:29:28 Accuracy: 42.424%\n",
            "03:29:28 Micro F-score: 0.424\n",
            "03:29:28 Weighted F-score: 0.351\n",
            "03:29:28 Saving model at save-frequency, at epoch 7, step 0\n",
            "03:29:28 Saving model, optimizer, and scheduler.\n",
            "03:29:39 ********** Completed epoch 8 **********\n",
            "03:29:39 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:29:39 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:29:40 Parameter Group `opt-1`: Starting epoch 9 with 50 steps and learning rate 1.00000E-05\n",
            "03:29:40 Evaluating model at test-frequency\n",
            "03:29:43 Obtained features, validation in progress\n",
            "03:29:43 Accuracy: 39.394%\n",
            "03:29:43 Micro F-score: 0.394\n",
            "03:29:43 Weighted F-score: 0.316\n",
            "03:29:43 Saving model at save-frequency, at epoch 8, step 0\n",
            "03:29:43 Saving model, optimizer, and scheduler.\n",
            "03:29:55 ********** Completed epoch 9 **********\n",
            "03:29:55 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:29:55 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:29:55 Parameter Group `opt-1`: Starting epoch 10 with 50 steps and learning rate 1.00000E-05\n",
            "03:29:56 Evaluating model at test-frequency\n",
            "03:29:59 Obtained features, validation in progress\n",
            "03:29:59 Accuracy: 38.384%\n",
            "03:29:59 Micro F-score: 0.384\n",
            "03:29:59 Weighted F-score: 0.302\n",
            "03:29:59 Saving model at save-frequency, at epoch 9, step 0\n",
            "03:29:59 Saving model, optimizer, and scheduler.\n",
            "03:30:10 ********** Completed epoch 10 **********\n",
            "03:30:10 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:30:10 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:30:10 Final: Evaluating model at test-frequency\n",
            "03:30:12 Obtained features, validation in progress\n",
            "03:30:12 Accuracy: 41.414%\n",
            "03:30:12 Micro F-score: 0.414\n",
            "03:30:12 Weighted F-score: 0.321\n",
            "03:30:12 Final: Saving model at save-frequency\n",
            "03:30:12 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk6APyy339AJ",
        "outputId": "db21ebff-e60f-4ceb-8095-04d8599eebc9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:30:32 Obtained features, validation in progress\n",
            "03:30:32 Accuracy: 41.414%\n",
            "03:30:32 Micro F-score: 0.414\n",
            "03:30:32 Weighted F-score: 0.321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Single classification (Vehicle Color)"
      ],
      "metadata": {
        "id": "BtW2Pdzd5jTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = \"color\"   # Make sure to change this to whatever name you used for make in your `original_tool_images` crawler\n",
        "class_idx = 2         # Make sure to change this to whetever index `color` is in your Crawler's tuple!\n",
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "f8Z9QLzP5j-b"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQzZN1Pl5oI4",
        "outputId": "0737f14d-b16a-454b-cb2f-fa1c9ab9252c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = \"./GLAMOR/profiles/CarZam/base_config.yml\", config_inject=[\n",
        "    (\"SAVE.MODEL_QUALIFIER\", class_name)\n",
        "])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXUBjgeJ5prE",
        "outputId": "0d21cd97-3e08-4c2e-8a2e-df4ab265aed2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, color\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bej6n_6h5sDd",
        "outputId": "c497d1f6-fd08-4efe-e323-89158a570213"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:35:24 ****************************************\n",
            "03:35:24 \n",
            "03:35:24 \n",
            "03:35:24 Using the following configuration:\n",
            "03:35:24 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx: 2\n",
            "      classificationclass: color\n",
            "      pathidx: 0\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: ClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: ''\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: out1\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: classification_model_builder\n",
            "  MODEL_ARCH: ClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS: {}\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: singleclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: color\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "03:35:24 \n",
            "03:35:24 \n",
            "03:35:24 ****************************************\n",
            "03:35:24 No previous stop detected. Will start from epoch 0\n",
            "03:35:24 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "03:35:24 Reading data with DataReader DataReader\n",
            "03:35:24 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "03:35:24 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "03:35:24 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "03:35:24 Updating GENERATOR to queued class ClassificationGenerator\n",
            "03:35:24 Updating CRAWLER to CarZamCrawler\n",
            "03:35:24 Generated training data generator with 1575 training data points\n",
            "03:35:24 Running classification model with classes: {'color': {'classes': 13}}\n",
            "03:35:24 Generated test data/query generator\n",
            "03:35:24 Loaded classification_model_builder from ednaml.models to build model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers\n",
            "\n",
            "types: ['ElectricVehicle', 'Wagon', 'Coupe', 'SUV', 'Van', 'PickupTruck', 'Sedan', 'Hybrid', 'LuxuryVehicle', 'Convertible', 'Diesel', 'SportsCar', 'Crossover']\n",
            "Tuple_expanded\n",
            "\n",
            "[('unzipped/original_tool_images/Hybrid Silver 2021 Toyota Avalon Hybrid.jpg', 7, 2, 0, 7), ('unzipped/original_tool_images/Crossover Black 2018 Jeep Compass.jpg', 12, 3, 5, 27), ('unzipped/original_tool_images/Sedan Gray 2017 Honda Fit.jpg', 6, 0, 8, 10), ('unzipped/original_tool_images/Pickup Truck Tan 2017 Toyota Tacoma.jpg', 5, 7, 8, 7), ('unzipped/original_tool_images/Luxury Vehicle Gold 2015 Cadillac CTS.jpg', 8, 11, 1, 18)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:35:25 Finished instantiating model with ClassificationResnet architecture\n",
            "03:35:25 Adding plugins after constructing model\n",
            "03:35:25 No saved model weights provided.\n",
            "03:35:25 Model Summary retured the following error:\n",
            "03:35:25 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "03:35:25 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "03:35:25 Built optimizer\n",
            "03:35:25 Built scheduler\n",
            "03:35:25 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "03:35:25 Built loss function\n",
            "03:35:25 Built loss optimizer\n",
            "03:35:25 Built loss scheduler\n",
            "03:35:25 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "03:35:25 Loaded ClassificationTrainer from ednaml.trainer to build Trainer\n",
            "03:35:25 Saving model metadata\n",
            "03:35:25 Backing up metadata\n",
            "03:35:25 Finished metadata backup\n",
            "03:35:25 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LSPY27Z5thR",
        "outputId": "fae372b5-f0bb-4db8-c127-c1163be4a347"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:35:28 Starting training\n",
            "03:35:28 Logging to:\torigtoolimgs-v1-singleclass-color-logger.log\n",
            "03:35:28 Models will be saved to local directory:\torigtoolimgs-v1-singleclass-color\n",
            "03:35:28 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "03:35:28 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "03:35:28 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "03:35:28 Performing initial evaluation...\n",
            "03:35:30 Obtained features, validation in progress\n",
            "03:35:30 Accuracy: 19.697%\n",
            "03:35:30 Micro F-score: 0.197\n",
            "03:35:30 Weighted F-score: 0.082\n",
            "03:35:30 Starting training from 0\n",
            "03:35:31 Parameter Group `opt-1`: Starting epoch 0 with 50 steps and learning rate 1.00000E-05\n",
            "03:35:44 ********** Completed epoch 0 **********\n",
            "03:35:44 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:35:44 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:35:45 Parameter Group `opt-1`: Starting epoch 1 with 50 steps and learning rate 1.00000E-05\n",
            "03:35:45 Evaluating model at test-frequency\n",
            "03:35:48 Obtained features, validation in progress\n",
            "03:35:48 Accuracy: 42.424%\n",
            "03:35:48 Micro F-score: 0.424\n",
            "03:35:48 Weighted F-score: 0.405\n",
            "03:35:48 Saving model at save-frequency, at epoch 0, step 0\n",
            "03:35:48 Saving model, optimizer, and scheduler.\n",
            "03:36:01 ********** Completed epoch 1 **********\n",
            "03:36:01 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:36:01 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:36:02 Parameter Group `opt-1`: Starting epoch 2 with 50 steps and learning rate 1.00000E-05\n",
            "03:36:02 Evaluating model at test-frequency\n",
            "03:36:05 Obtained features, validation in progress\n",
            "03:36:05 Accuracy: 65.152%\n",
            "03:36:05 Micro F-score: 0.652\n",
            "03:36:05 Weighted F-score: 0.594\n",
            "03:36:05 Saving model at save-frequency, at epoch 1, step 0\n",
            "03:36:05 Saving model, optimizer, and scheduler.\n",
            "03:36:20 ********** Completed epoch 2 **********\n",
            "03:36:20 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:36:20 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:36:21 Parameter Group `opt-1`: Starting epoch 3 with 50 steps and learning rate 1.00000E-05\n",
            "03:36:21 Evaluating model at test-frequency\n",
            "03:36:24 Obtained features, validation in progress\n",
            "03:36:24 Accuracy: 67.172%\n",
            "03:36:24 Micro F-score: 0.672\n",
            "03:36:24 Weighted F-score: 0.605\n",
            "03:36:24 Saving model at save-frequency, at epoch 2, step 0\n",
            "03:36:24 Saving model, optimizer, and scheduler.\n",
            "03:36:37 ********** Completed epoch 3 **********\n",
            "03:36:37 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:36:37 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:36:38 Parameter Group `opt-1`: Starting epoch 4 with 50 steps and learning rate 1.00000E-05\n",
            "03:36:39 Evaluating model at test-frequency\n",
            "03:36:42 Obtained features, validation in progress\n",
            "03:36:42 Accuracy: 69.697%\n",
            "03:36:42 Micro F-score: 0.697\n",
            "03:36:42 Weighted F-score: 0.633\n",
            "03:36:42 Saving model at save-frequency, at epoch 3, step 0\n",
            "03:36:42 Saving model, optimizer, and scheduler.\n",
            "03:36:54 ********** Completed epoch 4 **********\n",
            "03:36:54 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:36:54 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:36:55 Parameter Group `opt-1`: Starting epoch 5 with 50 steps and learning rate 1.00000E-05\n",
            "03:36:55 Evaluating model at test-frequency\n",
            "03:36:58 Obtained features, validation in progress\n",
            "03:36:58 Accuracy: 71.212%\n",
            "03:36:58 Micro F-score: 0.712\n",
            "03:36:58 Weighted F-score: 0.658\n",
            "03:36:58 Saving model at save-frequency, at epoch 4, step 0\n",
            "03:36:58 Saving model, optimizer, and scheduler.\n",
            "03:37:12 ********** Completed epoch 5 **********\n",
            "03:37:12 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:37:12 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:37:12 Parameter Group `opt-1`: Starting epoch 6 with 50 steps and learning rate 1.00000E-05\n",
            "03:37:13 Evaluating model at test-frequency\n",
            "03:37:16 Obtained features, validation in progress\n",
            "03:37:16 Accuracy: 71.212%\n",
            "03:37:16 Micro F-score: 0.712\n",
            "03:37:16 Weighted F-score: 0.659\n",
            "03:37:16 Saving model at save-frequency, at epoch 5, step 0\n",
            "03:37:16 Saving model, optimizer, and scheduler.\n",
            "03:37:29 ********** Completed epoch 6 **********\n",
            "03:37:29 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:37:29 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:37:29 Parameter Group `opt-1`: Starting epoch 7 with 50 steps and learning rate 1.00000E-05\n",
            "03:37:29 Evaluating model at test-frequency\n",
            "03:37:32 Obtained features, validation in progress\n",
            "03:37:32 Accuracy: 72.222%\n",
            "03:37:32 Micro F-score: 0.722\n",
            "03:37:32 Weighted F-score: 0.676\n",
            "03:37:32 Saving model at save-frequency, at epoch 6, step 0\n",
            "03:37:32 Saving model, optimizer, and scheduler.\n",
            "03:37:46 ********** Completed epoch 7 **********\n",
            "03:37:46 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:37:46 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:37:47 Parameter Group `opt-1`: Starting epoch 8 with 50 steps and learning rate 1.00000E-05\n",
            "03:37:47 Evaluating model at test-frequency\n",
            "03:37:50 Obtained features, validation in progress\n",
            "03:37:50 Accuracy: 72.727%\n",
            "03:37:50 Micro F-score: 0.727\n",
            "03:37:50 Weighted F-score: 0.679\n",
            "03:37:50 Saving model at save-frequency, at epoch 7, step 0\n",
            "03:37:50 Saving model, optimizer, and scheduler.\n",
            "03:38:03 ********** Completed epoch 8 **********\n",
            "03:38:03 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:38:03 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:38:03 Parameter Group `opt-1`: Starting epoch 9 with 50 steps and learning rate 1.00000E-05\n",
            "03:38:04 Evaluating model at test-frequency\n",
            "03:38:06 Obtained features, validation in progress\n",
            "03:38:06 Accuracy: 74.747%\n",
            "03:38:06 Micro F-score: 0.747\n",
            "03:38:06 Weighted F-score: 0.706\n",
            "03:38:06 Saving model at save-frequency, at epoch 8, step 0\n",
            "03:38:06 Saving model, optimizer, and scheduler.\n",
            "03:38:19 ********** Completed epoch 9 **********\n",
            "03:38:19 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:38:19 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:38:20 Parameter Group `opt-1`: Starting epoch 10 with 50 steps and learning rate 1.00000E-05\n",
            "03:38:21 Evaluating model at test-frequency\n",
            "03:38:24 Obtained features, validation in progress\n",
            "03:38:24 Accuracy: 75.253%\n",
            "03:38:24 Micro F-score: 0.753\n",
            "03:38:24 Weighted F-score: 0.709\n",
            "03:38:24 Saving model at save-frequency, at epoch 9, step 0\n",
            "03:38:24 Saving model, optimizer, and scheduler.\n",
            "03:38:36 ********** Completed epoch 10 **********\n",
            "03:38:36 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:38:36 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:38:36 Final: Evaluating model at test-frequency\n",
            "03:38:38 Obtained features, validation in progress\n",
            "03:38:38 Accuracy: 76.768%\n",
            "03:38:38 Micro F-score: 0.768\n",
            "03:38:38 Weighted F-score: 0.727\n",
            "03:38:38 Final: Saving model at save-frequency\n",
            "03:38:38 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xORIYrVT5uyR",
        "outputId": "4e531182-1098-425f-b017-2c8911e17f8d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:39:17 Obtained features, validation in progress\n",
            "03:39:17 Accuracy: 76.768%\n",
            "03:39:17 Micro F-score: 0.768\n",
            "03:39:17 Weighted F-score: 0.727\n"
          ]
        }
      ]
    }
  ]
}