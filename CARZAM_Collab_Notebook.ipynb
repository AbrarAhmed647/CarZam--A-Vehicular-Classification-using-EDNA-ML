{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: Abrar Ahmed Mohammed"
      ],
      "metadata": {
        "id": "m0bxr1CzADRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CARZAM Project Notebook"
      ],
      "metadata": {
        "id": "HvRdT0-WALX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading"
      ],
      "metadata": {
        "id": "IIvMmyor1zCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X2MfjyJ2rHy2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bc6d063a-764e-4e7f-e4f7-9d3e7bacb643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-03 12:31:45--  https://www.dropbox.com/s/pha9yzdfkmzoqob/original_tool_images.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/pha9yzdfkmzoqob/original_tool_images.zip [following]\n",
            "--2022-12-03 12:31:45--  https://www.dropbox.com/s/raw/pha9yzdfkmzoqob/original_tool_images.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc20617f0841f7dd35728328c931.dl.dropboxusercontent.com/cd/0/inline/Bx4KNe7vu4y38PmGoHX2zZNq8-r4RJkZ_-tfzKKxBmTJozu9bNDlfwpGq16hUEnsUQSY5BDj356dh-MuwZuoRz_3hb1w7cwxfHUXHuGARTZYaiGExMl5KHqWuPqcWT4tBFOTibkailLTtcEKOxZC3uKAyOjn4P8Fz6vjMczRLmlXhw/file# [following]\n",
            "--2022-12-03 12:31:45--  https://uc20617f0841f7dd35728328c931.dl.dropboxusercontent.com/cd/0/inline/Bx4KNe7vu4y38PmGoHX2zZNq8-r4RJkZ_-tfzKKxBmTJozu9bNDlfwpGq16hUEnsUQSY5BDj356dh-MuwZuoRz_3hb1w7cwxfHUXHuGARTZYaiGExMl5KHqWuPqcWT4tBFOTibkailLTtcEKOxZC3uKAyOjn4P8Fz6vjMczRLmlXhw/file\n",
            "Resolving uc20617f0841f7dd35728328c931.dl.dropboxusercontent.com (uc20617f0841f7dd35728328c931.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to uc20617f0841f7dd35728328c931.dl.dropboxusercontent.com (uc20617f0841f7dd35728328c931.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Bx4LzwzbdyHY88rwho_tr-HclZLQmx8TfS43Kjj9VMvAeLAE2jUbSytf12oAJQoc9up-E7EWO6hHziOpc0Za8qXRGPcqAvE861PucKeWAPM0XpHWKJwGJPH74tcFeSDhx9iEYZL-9VKomWYZlDVfCHU6MgVA90IAOowIGux-W8_Dqj5OkDMdispTWx9icNyaMdeqvJFxw8gNHTvQ0qnUmVvkRHKYqto0RpcQnreoV44IWZevo6Vdj_3QJmhsqLuKRF4748yaN4yDWhIHcYla_ddGDQFIMVWbc9HoIMzYttUoM-hTSMzuRoyAQRArulETZcPrknA-eY2XrovVyL5ZVsIlVTgVPfJn9SGG-vk0aDdSlrEKn4Kp8Ja5wn0pdhjWV-wl-cN9LXFS-cRr2wQg7I8Sk5qw2WU04_4PVJiEP9DzyQ/file [following]\n",
            "--2022-12-03 12:31:46--  https://uc20617f0841f7dd35728328c931.dl.dropboxusercontent.com/cd/0/inline2/Bx4LzwzbdyHY88rwho_tr-HclZLQmx8TfS43Kjj9VMvAeLAE2jUbSytf12oAJQoc9up-E7EWO6hHziOpc0Za8qXRGPcqAvE861PucKeWAPM0XpHWKJwGJPH74tcFeSDhx9iEYZL-9VKomWYZlDVfCHU6MgVA90IAOowIGux-W8_Dqj5OkDMdispTWx9icNyaMdeqvJFxw8gNHTvQ0qnUmVvkRHKYqto0RpcQnreoV44IWZevo6Vdj_3QJmhsqLuKRF4748yaN4yDWhIHcYla_ddGDQFIMVWbc9HoIMzYttUoM-hTSMzuRoyAQRArulETZcPrknA-eY2XrovVyL5ZVsIlVTgVPfJn9SGG-vk0aDdSlrEKn4Kp8Ja5wn0pdhjWV-wl-cN9LXFS-cRr2wQg7I8Sk5qw2WU04_4PVJiEP9DzyQ/file\n",
            "Reusing existing connection to uc20617f0841f7dd35728328c931.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87282712 (83M) [application/zip]\n",
            "Saving to: ‘original_tool_image.zip’\n",
            "\n",
            "original_tool_image 100%[===================>]  83.24M  99.3MB/s    in 0.8s    \n",
            "\n",
            "2022-12-03 12:31:48 (99.3 MB/s) - ‘original_tool_image.zip’ saved [87282712/87282712]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists('./original_tool_image.zip'):\n",
        "  ! wget -O original_tool_image.zip https://www.dropbox.com/s/pha9yzdfkmzoqob/original_tool_images.zip?dl=0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "_mtMC8V8r43T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqJoyEW1f_a1"
      },
      "source": [
        "## Git Clone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oisq4kE8IMHi"
      },
      "source": [
        "### From Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bJfycQTLVkEj"
      },
      "outputs": [],
      "source": [
        "! rm -rf -- GLAMOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "goBMKUmagBIx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6f8aba89-09d5-4f3a-d5bd-370a0c66146c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GLAMOR'...\n",
            "remote: Enumerating objects: 8567, done.\u001b[K\n",
            "remote: Counting objects: 100% (470/470), done.\u001b[K\n",
            "remote: Compressing objects: 100% (296/296), done.\u001b[K\n",
            "remote: Total 8567 (delta 247), reused 286 (delta 131), pack-reused 8097\u001b[K\n",
            "Receiving objects: 100% (8567/8567), 2.34 MiB | 4.40 MiB/s, done.\n",
            "Resolving deltas: 100% (5638/5638), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone -b master https://github.com/asuprem/GLAMOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T80AC-kx4v4Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d6efbebe-a9f9-48dc-a940-cfccc9dd210b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/GLAMOR\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (1.0.2)\n",
            "Requirement already satisfied: torch>=1.10.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (1.12.1+cu113)\n",
            "Collecting torchinfo>=1.6.5\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: torchvision>=0.11.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (0.13.1+cu113)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (7.1.2)\n",
            "Requirement already satisfied: tqdm>=4.63.* in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (4.64.1)\n",
            "Collecting sentencepiece>=0.1.96\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (2.4.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.8/dist-packages (from ednaml==0.1.5) (6.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.7.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.*->ednaml==0.1.5) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.11.*->ednaml==0.1.5) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (1.24.3)\n",
            "Installing collected packages: torchinfo, sentencepiece, ednaml\n",
            "  Running setup.py develop for ednaml\n",
            "Successfully installed ednaml-0.1.5 sentencepiece-0.1.97 torchinfo-1.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -e GLAMOR/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5j3WfN0fpIT"
      },
      "source": [
        "###  From PyPi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7dkOhZi08dU"
      },
      "outputs": [],
      "source": [
        "#! python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwqgjiZ331ik"
      },
      "outputs": [],
      "source": [
        "#! pip3 install --pre ednaml==0.1.4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restart Notebook to Finish EdnaML Installation"
      ],
      "metadata": {
        "id": "84c7mTxBr7Sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up"
      ],
      "metadata": {
        "id": "j6-WuaR3sX5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "rW5_Xxhvr7IT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import ednaml\n",
        "import glob, os\n",
        "#from ednaml.core import EdnaDeploy, EdnaML\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "zXxdpMEtr7GG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "64fd2543-64a8-4302-e45e-6beeb9c9e236"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.1+cu113'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definitions: Crawler"
      ],
      "metadata": {
        "id": "9PfHu-KZsQ9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we define our custom model class\n",
        "from ednaml.crawlers import Crawler\n",
        "from zipfile import ZipFile # might be useful in unzipping!\n",
        "\n",
        "class CarZamCrawler(Crawler):\n",
        "  def __init__(self, logger, file_name = \"original_tool_images.zip\", **kwargs): # Add your own arguments if needed!\n",
        "    self.classes = {}\n",
        "    self.metadata = {}\n",
        "    self.metadata[\"train\"] = {}\n",
        "    self.metadata[\"test\"] = {}\n",
        "    self.metadata[\"val\"] = {}\n",
        "    self.metadata[\"train\"][\"crawl\"] = []  # <------ THIS NEEDS TO BE POPULATED\n",
        "    self.metadata[\"test\"][\"crawl\"] = []   # <------ THIS NEEDS TO BE POPULATED\n",
        "    self.metadata[\"val\"][\"crawl\"] = []    # <------ THIS NEEDS TO BE POPULATED\n",
        "\n",
        "    # YOUR CODE HERE ------ POPULATE self.classes and self.metadata's empty lists ---\n",
        "    from zipfile import ZipFile\n",
        "    file_name = \"original_tool_image.zip\"\n",
        "    fdest= \"unzipped\"\n",
        "    if not os.path.exists(fdest):\n",
        "      with ZipFile(file_name, 'r') as zip: \n",
        "          # extract all files to another directory\n",
        "          zip.extractall(fdest)\n",
        "    fllist = glob.glob(os.path.join(fdest, \"original_tool_images/*.jpg\"))\n",
        "    #tuple_prelim = [self.getinittuple(item) for item in fllist]\n",
        "    temp=[]\n",
        "    #ans=[]\n",
        "    tokeep = [\"Convertible\", \"Coupe\", \"Crossover\", \"Diesel\", \"Hybrid\", \"Sedan\", \"SUV\", \"Wagon\",\"SportsCar\", \"Truck\", \"Van\", ]\n",
        "    tuple_expanded=[]\n",
        "    for item in fllist:\n",
        "      tuple_prelim=os.path.splitext(os.path.basename(item))[0].split(\" \"), item\n",
        "      #print(tuple_prelim)\n",
        "      if(len(tuple_prelim[0])==5):\n",
        "        temp.append(tuple_prelim[1]) #appending path\n",
        "        for i in tuple_prelim[0]:  #appending type,color,year,make,model\n",
        "            if(i==\"CoupeBlack\"):\n",
        "             temp.append(\"Coupe\")\n",
        "             temp.append(\"Black\")\n",
        "             temp.append(tuple_prelim[1:])\n",
        "            else:\n",
        "              temp.append(i)\n",
        "        \n",
        "        my_tuple=tuple(temp)        #list to Tuple\n",
        "        tuple_expanded.append(my_tuple)   \n",
        "        temp=[]\n",
        "      elif(len(tuple_prelim[0])==6):\n",
        "        temp.append(tuple_prelim[1])\n",
        "        if(tuple_prelim[0][0]) in tokeep:\n",
        "          for i in tuple_prelim[0][:4]:\n",
        "            temp.append(i)\n",
        "          temp.append(tuple_prelim[0][4]+tuple_prelim[0][5])\n",
        "\n",
        "          my_tuple=tuple(temp)\n",
        "          tuple_expanded.append(my_tuple)\n",
        "          temp=[]\n",
        "        else:\n",
        "          temp.append(tuple_prelim[0][0]+tuple_prelim[0][1])\n",
        "          for i in tuple_prelim[0][2:]:\n",
        "            temp.append(i)\n",
        "          #temp.append(tuple_prelim[1])\n",
        "          my_tuple=tuple(temp)\n",
        "          tuple_expanded.append(my_tuple)\n",
        "          temp=[]\n",
        "  #print(ans)\n",
        "      elif(len(tuple_prelim[0])==7):\n",
        "        temp.append(tuple_prelim[1])\n",
        "        if tuple_prelim[0][0] in tokeep:\n",
        "          for i in tuple_prelim[0][:4]:\n",
        "            temp.append(i)\n",
        "          temp.append(tuple_prelim[0][4:])\n",
        "\n",
        "          my_tuple=tuple(temp)\n",
        "          tuple_expanded.append(my_tuple)\n",
        "          temp=[]\n",
        "        else:\n",
        "          temp.append(tuple_prelim[0][0]+tuple_prelim[0][1])\n",
        "          for i in tuple_prelim[0][2:5]:\n",
        "            temp.append(i)\n",
        "          temp.append(tuple_prelim[0][5]+tuple_prelim[0][6])\n",
        "        \n",
        "          my_tuple=tuple(temp)\n",
        "          tuple_expanded.append(my_tuple)\n",
        "          temp=[]\n",
        "    #print(\"Tuple_expanded:\")\n",
        "    #print(tuple_expanded[0])\n",
        "    import random\n",
        "    random.seed(3456)\n",
        "    random.shuffle(tuple_expanded)\n",
        "\n",
        "    splits = 0.8\n",
        "    train_sets = int(len(tuple_expanded)*0.8)\n",
        "    val_sets = int(len(tuple_expanded)*0.1)\n",
        "\n",
        "    \n",
        "\n",
        "    # structure:  (path, type, color, year, make)\n",
        "    # idx           0     1     2     3     4\n",
        "    print(\"Outliers\\n\")\n",
        "    for item in tuple_expanded:\n",
        "      if(item[1]=='CoupeBlack'):\n",
        "        print(item)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    types = list(set([item[1] for item in tuple_expanded]))\n",
        "    print(\"types:\",types)\n",
        "    colors = list(set([item[2] for item in tuple_expanded]))\n",
        "    years = list(set([item[3] for item in tuple_expanded]))\n",
        "    makes = list(set([item[4] for item in tuple_expanded]))\n",
        "\n",
        "    self.classes[\"vtype\"] = len(types)\n",
        "    self.classes[\"color\"] = len(colors)\n",
        "    self.classes[\"year\"] = len(years)\n",
        "    self.classes[\"make\"] = len(makes)\n",
        "\n",
        "    self.type_lookup = {item:idx for idx,item in enumerate(types)}\n",
        "    self.color_lookup = {item:idx for idx,item in enumerate(colors)}\n",
        "    self.year_lookup = {item:idx for idx,item in enumerate(years)}\n",
        "    self.make_lookup = {item:idx for idx,item in enumerate(makes)}\n",
        "    \n",
        "    tuple_ex=tuple_expanded\n",
        "    tuple_expanded = [(item[0], self.type_lookup[item[1]], self.color_lookup[item[2]], self.year_lookup[item[3]], self.make_lookup[item[4]]) for item in tuple_expanded]\n",
        "    print(\"\\n\")\n",
        "    print(\"Tuple_expanded\\n\")\n",
        "    print(tuple_expanded[:5])\n",
        "\n",
        "    #split the datasets\n",
        "    self.metadata[\"train\"][\"crawl\"] = tuple_expanded[:train_sets]\n",
        "    self.metadata[\"val\"][\"crawl\"] = tuple_expanded[train_sets:val_sets]\n",
        "    self.metadata[\"test\"][\"crawl\"] = tuple_expanded[train_sets+val_sets:]\n",
        "\n",
        "\n",
        "    # -------------------------------------------------------------------------------\n",
        "\n",
        "    self.metadata[\"train\"][\"classes\"] = self.classes\n",
        "    self.metadata[\"test\"][\"classes\"] = self.classes\n",
        "    self.metadata[\"val\"][\"classes\"] = self.classes\n",
        "\n",
        "  def getinittuple(self, item):\n",
        "    return (os.path.splitext(os.path.basename(item))[0].split(\" \"), item)\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "-2z_FeuUsSr6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Crawler"
      ],
      "metadata": {
        "id": "_GzkE8ymuUj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"logger\" : None,\n",
        "    \"file_name\" : \"original_tool_images.zip\",\n",
        "    # add any other kwargs here...\n",
        "}"
      ],
      "metadata": {
        "id": "x0GIxddZuarz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crawler = CarZamCrawler(**kwargs)"
      ],
      "metadata": {
        "id": "BIGL8tGzuWs7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "400959b2-529e-48b1-ada0-d3d14b5f22e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers\n",
            "\n",
            "types: ['Coupe', 'Wagon', 'Hybrid', 'LuxuryVehicle', 'Diesel', 'SUV', 'Convertible', 'PickupTruck', 'Van', 'Crossover', 'ElectricVehicle', 'SportsCar', 'Sedan']\n",
            "Tuple_expanded\n",
            "\n",
            "[('unzipped/original_tool_images/Sedan Blue 2016 Mercedes-Benz E350.jpg', 12, 0, 12, 19), ('unzipped/original_tool_images/Crossover White 2017 Chevrolet Equinox.jpg', 9, 9, 4, 23), ('unzipped/original_tool_images/Sports Car White 2017 Chevrolet Corvette.jpg', 11, 9, 4, 23), ('unzipped/original_tool_images/Sedan Silver 2020 Honda Accord.jpg', 12, 11, 8, 27), ('unzipped/original_tool_images/Sedan Black 2015 BMW 550.jpg', 12, 7, 10, 6)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crawler.classes # You should get the classes here"
      ],
      "metadata": {
        "id": "bf3QLBgWuouh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bb5da0dd-3af8-4fd4-ccee-693a575f0cbf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vtype': 13, 'color': 13, 'year': 14, 'make': 36}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crawler.metadata[\"train\"][\"crawl\"][:5]  # You should get the list of tuples here"
      ],
      "metadata": {
        "id": "Aud7dfjGunhE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "04ebe221-882b-444d-dd2c-edc40fd7025b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('unzipped/original_tool_images/Sedan Blue 2016 Mercedes-Benz E350.jpg',\n",
              "  12,\n",
              "  0,\n",
              "  12,\n",
              "  19),\n",
              " ('unzipped/original_tool_images/Crossover White 2017 Chevrolet Equinox.jpg',\n",
              "  9,\n",
              "  9,\n",
              "  4,\n",
              "  23),\n",
              " ('unzipped/original_tool_images/Sports Car White 2017 Chevrolet Corvette.jpg',\n",
              "  11,\n",
              "  9,\n",
              "  4,\n",
              "  23),\n",
              " ('unzipped/original_tool_images/Sedan Silver 2020 Honda Accord.jpg',\n",
              "  12,\n",
              "  11,\n",
              "  8,\n",
              "  27),\n",
              " ('unzipped/original_tool_images/Sedan Black 2015 BMW 550.jpg', 12, 7, 10, 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistics"
      ],
      "metadata": {
        "id": "l6_TufwByRmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dO9dJ0R-1Io0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code to collect info on # makes, models, year, type\n",
        "#\n",
        "#\n",
        "for i in crawler.classes:\n",
        "  plt.bar(i,crawler.classes[i])\n"
      ],
      "metadata": {
        "id": "7yRF6u3MySi2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cd298590-bfdd-44c9-c5d1-bd616b4a0ba9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c_kd38y2_tWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 Single classification (Vehicle Type)"
      ],
      "metadata": {
        "id": "1FfnWjLr2YnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = \"vtype\"  # Make sure to change this to whatever name you used for make in your `original_tool_images` crawler\n",
        "class_idx = 1         # Make sure to change this to whetever index `type` is in your Crawler's tuple!\n",
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "3TklNIgR2a9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDaa1wOf24HB",
        "outputId": "9cd1fd9c-2e79-4276-99a8-b1e5a6f9696d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = \"./GLAMOR/profiles/CarZam/base_config.yml\", config_inject=[\n",
        "    (\"SAVE.MODEL_QUALIFIER\", class_name)\n",
        "])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtj3SqdS24Js",
        "outputId": "6e264aca-085e-4bf8-9236-c465bfde0c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, vtype\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQXyMY8s24NH",
        "outputId": "349b375a-7f3a-4324-eadc-02e5956bed12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:26:57 ****************************************\n",
            "03:26:57 \n",
            "03:26:57 \n",
            "03:26:57 Using the following configuration:\n",
            "03:26:57 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx: 1\n",
            "      classificationclass: vtype\n",
            "      pathidx: 0\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: ClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: ''\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: out1\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: classification_model_builder\n",
            "  MODEL_ARCH: ClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS: {}\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: singleclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: vtype\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "03:26:57 \n",
            "03:26:57 \n",
            "03:26:57 ****************************************\n",
            "03:26:57 Model weights file resnet18-5c106cde.pth does not exist. Downloading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46827520/46827520 bytes [████████████████████████████████████████████████████████████████████████████████████████████████████]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:26:57 No previous stop detected. Will start from epoch 0\n",
            "03:26:57 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "03:26:57 Reading data with DataReader DataReader\n",
            "03:26:57 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "03:26:57 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "03:26:57 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "03:26:57 Updating GENERATOR to queued class ClassificationGenerator\n",
            "03:26:57 Updating CRAWLER to CarZamCrawler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Download of resnet18-5c106cde.pth to https://download.pytorch.org/models/resnet18-5c106cde.pth completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:26:57 Generated training data generator with 1575 training data points\n",
            "03:26:57 Running classification model with classes: {'vtype': {'classes': 13}}\n",
            "03:26:57 Generated test data/query generator\n",
            "03:26:57 Loaded classification_model_builder from ednaml.models to build model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers\n",
            "\n",
            "types: ['ElectricVehicle', 'Wagon', 'Coupe', 'SUV', 'Van', 'PickupTruck', 'Sedan', 'Hybrid', 'LuxuryVehicle', 'Convertible', 'Diesel', 'SportsCar', 'Crossover']\n",
            "Tuple_expanded\n",
            "\n",
            "[('unzipped/original_tool_images/Hybrid Silver 2021 Toyota Avalon Hybrid.jpg', 7, 2, 0, 7), ('unzipped/original_tool_images/Crossover Black 2018 Jeep Compass.jpg', 12, 3, 5, 27), ('unzipped/original_tool_images/Sedan Gray 2017 Honda Fit.jpg', 6, 0, 8, 10), ('unzipped/original_tool_images/Pickup Truck Tan 2017 Toyota Tacoma.jpg', 5, 7, 8, 7), ('unzipped/original_tool_images/Luxury Vehicle Gold 2015 Cadillac CTS.jpg', 8, 11, 1, 18)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:26:58 Finished instantiating model with ClassificationResnet architecture\n",
            "03:26:58 Adding plugins after constructing model\n",
            "03:26:58 No saved model weights provided.\n",
            "03:27:02 Model Summary retured the following error:\n",
            "03:27:02 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "03:27:02 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "03:27:02 Built optimizer\n",
            "03:27:02 Built scheduler\n",
            "03:27:02 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "03:27:02 Built loss function\n",
            "03:27:02 Built loss optimizer\n",
            "03:27:02 Built loss scheduler\n",
            "03:27:02 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "03:27:02 Loaded ClassificationTrainer from ednaml.trainer to build Trainer\n",
            "03:27:02 Saving model metadata\n",
            "03:27:02 Backing up metadata\n",
            "03:27:02 Finished metadata backup\n",
            "03:27:02 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3DgrZI53vDA",
        "outputId": "8425ab24-b2fd-4d79-b165-e0981f9c1912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:27:13 Starting training\n",
            "03:27:13 Logging to:\torigtoolimgs-v1-singleclass-vtype-logger.log\n",
            "03:27:13 Models will be saved to local directory:\torigtoolimgs-v1-singleclass-vtype\n",
            "03:27:13 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "03:27:13 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "03:27:13 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "03:27:13 Performing initial evaluation...\n",
            "03:27:20 Obtained features, validation in progress\n",
            "03:27:20 Accuracy: 14.141%\n",
            "03:27:20 Micro F-score: 0.141\n",
            "03:27:20 Weighted F-score: 0.063\n",
            "03:27:20 Starting training from 0\n",
            "03:27:21 Parameter Group `opt-1`: Starting epoch 0 with 50 steps and learning rate 1.00000E-05\n",
            "03:27:35 ********** Completed epoch 0 **********\n",
            "03:27:35 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:27:35 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:27:35 Parameter Group `opt-1`: Starting epoch 1 with 50 steps and learning rate 1.00000E-05\n",
            "03:27:36 Evaluating model at test-frequency\n",
            "03:27:38 Obtained features, validation in progress\n",
            "03:27:38 Accuracy: 28.788%\n",
            "03:27:38 Micro F-score: 0.288\n",
            "03:27:38 Weighted F-score: 0.287\n",
            "03:27:38 Saving model at save-frequency, at epoch 0, step 0\n",
            "03:27:38 Saving model, optimizer, and scheduler.\n",
            "03:27:50 ********** Completed epoch 1 **********\n",
            "03:27:50 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:27:50 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:27:51 Parameter Group `opt-1`: Starting epoch 2 with 50 steps and learning rate 1.00000E-05\n",
            "03:27:52 Evaluating model at test-frequency\n",
            "03:27:54 Obtained features, validation in progress\n",
            "03:27:54 Accuracy: 38.889%\n",
            "03:27:54 Micro F-score: 0.389\n",
            "03:27:54 Weighted F-score: 0.362\n",
            "03:27:54 Saving model at save-frequency, at epoch 1, step 0\n",
            "03:27:54 Saving model, optimizer, and scheduler.\n",
            "03:28:06 ********** Completed epoch 2 **********\n",
            "03:28:06 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:28:06 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:28:06 Parameter Group `opt-1`: Starting epoch 3 with 50 steps and learning rate 1.00000E-05\n",
            "03:28:07 Evaluating model at test-frequency\n",
            "03:28:09 Obtained features, validation in progress\n",
            "03:28:09 Accuracy: 41.919%\n",
            "03:28:09 Micro F-score: 0.419\n",
            "03:28:09 Weighted F-score: 0.391\n",
            "03:28:09 Saving model at save-frequency, at epoch 2, step 0\n",
            "03:28:09 Saving model, optimizer, and scheduler.\n",
            "03:28:22 ********** Completed epoch 3 **********\n",
            "03:28:22 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:28:22 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:28:22 Parameter Group `opt-1`: Starting epoch 4 with 50 steps and learning rate 1.00000E-05\n",
            "03:28:23 Evaluating model at test-frequency\n",
            "03:28:26 Obtained features, validation in progress\n",
            "03:28:26 Accuracy: 40.404%\n",
            "03:28:26 Micro F-score: 0.404\n",
            "03:28:26 Weighted F-score: 0.360\n",
            "03:28:26 Saving model at save-frequency, at epoch 3, step 0\n",
            "03:28:26 Saving model, optimizer, and scheduler.\n",
            "03:28:37 ********** Completed epoch 4 **********\n",
            "03:28:37 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:28:37 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:28:38 Parameter Group `opt-1`: Starting epoch 5 with 50 steps and learning rate 1.00000E-05\n",
            "03:28:38 Evaluating model at test-frequency\n",
            "03:28:41 Obtained features, validation in progress\n",
            "03:28:41 Accuracy: 41.919%\n",
            "03:28:41 Micro F-score: 0.419\n",
            "03:28:41 Weighted F-score: 0.375\n",
            "03:28:41 Saving model at save-frequency, at epoch 4, step 0\n",
            "03:28:41 Saving model, optimizer, and scheduler.\n",
            "03:28:52 ********** Completed epoch 5 **********\n",
            "03:28:52 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:28:52 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:28:53 Parameter Group `opt-1`: Starting epoch 6 with 50 steps and learning rate 1.00000E-05\n",
            "03:28:54 Evaluating model at test-frequency\n",
            "03:28:56 Obtained features, validation in progress\n",
            "03:28:56 Accuracy: 38.384%\n",
            "03:28:56 Micro F-score: 0.384\n",
            "03:28:56 Weighted F-score: 0.326\n",
            "03:28:56 Saving model at save-frequency, at epoch 5, step 0\n",
            "03:28:56 Saving model, optimizer, and scheduler.\n",
            "03:29:08 ********** Completed epoch 6 **********\n",
            "03:29:08 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:29:08 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:29:09 Parameter Group `opt-1`: Starting epoch 7 with 50 steps and learning rate 1.00000E-05\n",
            "03:29:09 Evaluating model at test-frequency\n",
            "03:29:12 Obtained features, validation in progress\n",
            "03:29:12 Accuracy: 39.394%\n",
            "03:29:12 Micro F-score: 0.394\n",
            "03:29:12 Weighted F-score: 0.325\n",
            "03:29:12 Saving model at save-frequency, at epoch 6, step 0\n",
            "03:29:12 Saving model, optimizer, and scheduler.\n",
            "03:29:24 ********** Completed epoch 7 **********\n",
            "03:29:24 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:29:24 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:29:24 Parameter Group `opt-1`: Starting epoch 8 with 50 steps and learning rate 1.00000E-05\n",
            "03:29:25 Evaluating model at test-frequency\n",
            "03:29:28 Obtained features, validation in progress\n",
            "03:29:28 Accuracy: 42.424%\n",
            "03:29:28 Micro F-score: 0.424\n",
            "03:29:28 Weighted F-score: 0.351\n",
            "03:29:28 Saving model at save-frequency, at epoch 7, step 0\n",
            "03:29:28 Saving model, optimizer, and scheduler.\n",
            "03:29:39 ********** Completed epoch 8 **********\n",
            "03:29:39 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:29:39 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:29:40 Parameter Group `opt-1`: Starting epoch 9 with 50 steps and learning rate 1.00000E-05\n",
            "03:29:40 Evaluating model at test-frequency\n",
            "03:29:43 Obtained features, validation in progress\n",
            "03:29:43 Accuracy: 39.394%\n",
            "03:29:43 Micro F-score: 0.394\n",
            "03:29:43 Weighted F-score: 0.316\n",
            "03:29:43 Saving model at save-frequency, at epoch 8, step 0\n",
            "03:29:43 Saving model, optimizer, and scheduler.\n",
            "03:29:55 ********** Completed epoch 9 **********\n",
            "03:29:55 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:29:55 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:29:55 Parameter Group `opt-1`: Starting epoch 10 with 50 steps and learning rate 1.00000E-05\n",
            "03:29:56 Evaluating model at test-frequency\n",
            "03:29:59 Obtained features, validation in progress\n",
            "03:29:59 Accuracy: 38.384%\n",
            "03:29:59 Micro F-score: 0.384\n",
            "03:29:59 Weighted F-score: 0.302\n",
            "03:29:59 Saving model at save-frequency, at epoch 9, step 0\n",
            "03:29:59 Saving model, optimizer, and scheduler.\n",
            "03:30:10 ********** Completed epoch 10 **********\n",
            "03:30:10 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:30:10 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:30:10 Final: Evaluating model at test-frequency\n",
            "03:30:12 Obtained features, validation in progress\n",
            "03:30:12 Accuracy: 41.414%\n",
            "03:30:12 Micro F-score: 0.414\n",
            "03:30:12 Weighted F-score: 0.321\n",
            "03:30:12 Final: Saving model at save-frequency\n",
            "03:30:12 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk6APyy339AJ",
        "outputId": "db21ebff-e60f-4ceb-8095-04d8599eebc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:30:32 Obtained features, validation in progress\n",
            "03:30:32 Accuracy: 41.414%\n",
            "03:30:32 Micro F-score: 0.414\n",
            "03:30:32 Weighted F-score: 0.321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Single classification (Vehicle Color)"
      ],
      "metadata": {
        "id": "BtW2Pdzd5jTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = \"color\"   # Make sure to change this to whatever name you used for make in your `original_tool_images` crawler\n",
        "class_idx = 2         # Make sure to change this to whetever index `color` is in your Crawler's tuple!\n",
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "f8Z9QLzP5j-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQzZN1Pl5oI4",
        "outputId": "0737f14d-b16a-454b-cb2f-fa1c9ab9252c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = \"./GLAMOR/profiles/CarZam/base_config.yml\", config_inject=[\n",
        "    (\"SAVE.MODEL_QUALIFIER\", class_name)\n",
        "])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXUBjgeJ5prE",
        "outputId": "0d21cd97-3e08-4c2e-8a2e-df4ab265aed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, color\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bej6n_6h5sDd",
        "outputId": "c497d1f6-fd08-4efe-e323-89158a570213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:35:24 ****************************************\n",
            "03:35:24 \n",
            "03:35:24 \n",
            "03:35:24 Using the following configuration:\n",
            "03:35:24 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx: 2\n",
            "      classificationclass: color\n",
            "      pathidx: 0\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: ClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: ''\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: out1\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: classification_model_builder\n",
            "  MODEL_ARCH: ClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS: {}\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: singleclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: color\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "03:35:24 \n",
            "03:35:24 \n",
            "03:35:24 ****************************************\n",
            "03:35:24 No previous stop detected. Will start from epoch 0\n",
            "03:35:24 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "03:35:24 Reading data with DataReader DataReader\n",
            "03:35:24 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "03:35:24 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "03:35:24 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "03:35:24 Updating GENERATOR to queued class ClassificationGenerator\n",
            "03:35:24 Updating CRAWLER to CarZamCrawler\n",
            "03:35:24 Generated training data generator with 1575 training data points\n",
            "03:35:24 Running classification model with classes: {'color': {'classes': 13}}\n",
            "03:35:24 Generated test data/query generator\n",
            "03:35:24 Loaded classification_model_builder from ednaml.models to build model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers\n",
            "\n",
            "types: ['ElectricVehicle', 'Wagon', 'Coupe', 'SUV', 'Van', 'PickupTruck', 'Sedan', 'Hybrid', 'LuxuryVehicle', 'Convertible', 'Diesel', 'SportsCar', 'Crossover']\n",
            "Tuple_expanded\n",
            "\n",
            "[('unzipped/original_tool_images/Hybrid Silver 2021 Toyota Avalon Hybrid.jpg', 7, 2, 0, 7), ('unzipped/original_tool_images/Crossover Black 2018 Jeep Compass.jpg', 12, 3, 5, 27), ('unzipped/original_tool_images/Sedan Gray 2017 Honda Fit.jpg', 6, 0, 8, 10), ('unzipped/original_tool_images/Pickup Truck Tan 2017 Toyota Tacoma.jpg', 5, 7, 8, 7), ('unzipped/original_tool_images/Luxury Vehicle Gold 2015 Cadillac CTS.jpg', 8, 11, 1, 18)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:35:25 Finished instantiating model with ClassificationResnet architecture\n",
            "03:35:25 Adding plugins after constructing model\n",
            "03:35:25 No saved model weights provided.\n",
            "03:35:25 Model Summary retured the following error:\n",
            "03:35:25 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "03:35:25 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "03:35:25 Built optimizer\n",
            "03:35:25 Built scheduler\n",
            "03:35:25 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "03:35:25 Built loss function\n",
            "03:35:25 Built loss optimizer\n",
            "03:35:25 Built loss scheduler\n",
            "03:35:25 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "03:35:25 Loaded ClassificationTrainer from ednaml.trainer to build Trainer\n",
            "03:35:25 Saving model metadata\n",
            "03:35:25 Backing up metadata\n",
            "03:35:25 Finished metadata backup\n",
            "03:35:25 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LSPY27Z5thR",
        "outputId": "fae372b5-f0bb-4db8-c127-c1163be4a347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:35:28 Starting training\n",
            "03:35:28 Logging to:\torigtoolimgs-v1-singleclass-color-logger.log\n",
            "03:35:28 Models will be saved to local directory:\torigtoolimgs-v1-singleclass-color\n",
            "03:35:28 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "03:35:28 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "03:35:28 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "03:35:28 Performing initial evaluation...\n",
            "03:35:30 Obtained features, validation in progress\n",
            "03:35:30 Accuracy: 19.697%\n",
            "03:35:30 Micro F-score: 0.197\n",
            "03:35:30 Weighted F-score: 0.082\n",
            "03:35:30 Starting training from 0\n",
            "03:35:31 Parameter Group `opt-1`: Starting epoch 0 with 50 steps and learning rate 1.00000E-05\n",
            "03:35:44 ********** Completed epoch 0 **********\n",
            "03:35:44 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:35:44 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:35:45 Parameter Group `opt-1`: Starting epoch 1 with 50 steps and learning rate 1.00000E-05\n",
            "03:35:45 Evaluating model at test-frequency\n",
            "03:35:48 Obtained features, validation in progress\n",
            "03:35:48 Accuracy: 42.424%\n",
            "03:35:48 Micro F-score: 0.424\n",
            "03:35:48 Weighted F-score: 0.405\n",
            "03:35:48 Saving model at save-frequency, at epoch 0, step 0\n",
            "03:35:48 Saving model, optimizer, and scheduler.\n",
            "03:36:01 ********** Completed epoch 1 **********\n",
            "03:36:01 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:36:01 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:36:02 Parameter Group `opt-1`: Starting epoch 2 with 50 steps and learning rate 1.00000E-05\n",
            "03:36:02 Evaluating model at test-frequency\n",
            "03:36:05 Obtained features, validation in progress\n",
            "03:36:05 Accuracy: 65.152%\n",
            "03:36:05 Micro F-score: 0.652\n",
            "03:36:05 Weighted F-score: 0.594\n",
            "03:36:05 Saving model at save-frequency, at epoch 1, step 0\n",
            "03:36:05 Saving model, optimizer, and scheduler.\n",
            "03:36:20 ********** Completed epoch 2 **********\n",
            "03:36:20 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:36:20 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:36:21 Parameter Group `opt-1`: Starting epoch 3 with 50 steps and learning rate 1.00000E-05\n",
            "03:36:21 Evaluating model at test-frequency\n",
            "03:36:24 Obtained features, validation in progress\n",
            "03:36:24 Accuracy: 67.172%\n",
            "03:36:24 Micro F-score: 0.672\n",
            "03:36:24 Weighted F-score: 0.605\n",
            "03:36:24 Saving model at save-frequency, at epoch 2, step 0\n",
            "03:36:24 Saving model, optimizer, and scheduler.\n",
            "03:36:37 ********** Completed epoch 3 **********\n",
            "03:36:37 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:36:37 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:36:38 Parameter Group `opt-1`: Starting epoch 4 with 50 steps and learning rate 1.00000E-05\n",
            "03:36:39 Evaluating model at test-frequency\n",
            "03:36:42 Obtained features, validation in progress\n",
            "03:36:42 Accuracy: 69.697%\n",
            "03:36:42 Micro F-score: 0.697\n",
            "03:36:42 Weighted F-score: 0.633\n",
            "03:36:42 Saving model at save-frequency, at epoch 3, step 0\n",
            "03:36:42 Saving model, optimizer, and scheduler.\n",
            "03:36:54 ********** Completed epoch 4 **********\n",
            "03:36:54 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:36:54 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:36:55 Parameter Group `opt-1`: Starting epoch 5 with 50 steps and learning rate 1.00000E-05\n",
            "03:36:55 Evaluating model at test-frequency\n",
            "03:36:58 Obtained features, validation in progress\n",
            "03:36:58 Accuracy: 71.212%\n",
            "03:36:58 Micro F-score: 0.712\n",
            "03:36:58 Weighted F-score: 0.658\n",
            "03:36:58 Saving model at save-frequency, at epoch 4, step 0\n",
            "03:36:58 Saving model, optimizer, and scheduler.\n",
            "03:37:12 ********** Completed epoch 5 **********\n",
            "03:37:12 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:37:12 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:37:12 Parameter Group `opt-1`: Starting epoch 6 with 50 steps and learning rate 1.00000E-05\n",
            "03:37:13 Evaluating model at test-frequency\n",
            "03:37:16 Obtained features, validation in progress\n",
            "03:37:16 Accuracy: 71.212%\n",
            "03:37:16 Micro F-score: 0.712\n",
            "03:37:16 Weighted F-score: 0.659\n",
            "03:37:16 Saving model at save-frequency, at epoch 5, step 0\n",
            "03:37:16 Saving model, optimizer, and scheduler.\n",
            "03:37:29 ********** Completed epoch 6 **********\n",
            "03:37:29 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:37:29 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:37:29 Parameter Group `opt-1`: Starting epoch 7 with 50 steps and learning rate 1.00000E-05\n",
            "03:37:29 Evaluating model at test-frequency\n",
            "03:37:32 Obtained features, validation in progress\n",
            "03:37:32 Accuracy: 72.222%\n",
            "03:37:32 Micro F-score: 0.722\n",
            "03:37:32 Weighted F-score: 0.676\n",
            "03:37:32 Saving model at save-frequency, at epoch 6, step 0\n",
            "03:37:32 Saving model, optimizer, and scheduler.\n",
            "03:37:46 ********** Completed epoch 7 **********\n",
            "03:37:46 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:37:46 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:37:47 Parameter Group `opt-1`: Starting epoch 8 with 50 steps and learning rate 1.00000E-05\n",
            "03:37:47 Evaluating model at test-frequency\n",
            "03:37:50 Obtained features, validation in progress\n",
            "03:37:50 Accuracy: 72.727%\n",
            "03:37:50 Micro F-score: 0.727\n",
            "03:37:50 Weighted F-score: 0.679\n",
            "03:37:50 Saving model at save-frequency, at epoch 7, step 0\n",
            "03:37:50 Saving model, optimizer, and scheduler.\n",
            "03:38:03 ********** Completed epoch 8 **********\n",
            "03:38:03 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:38:03 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:38:03 Parameter Group `opt-1`: Starting epoch 9 with 50 steps and learning rate 1.00000E-05\n",
            "03:38:04 Evaluating model at test-frequency\n",
            "03:38:06 Obtained features, validation in progress\n",
            "03:38:06 Accuracy: 74.747%\n",
            "03:38:06 Micro F-score: 0.747\n",
            "03:38:06 Weighted F-score: 0.706\n",
            "03:38:06 Saving model at save-frequency, at epoch 8, step 0\n",
            "03:38:06 Saving model, optimizer, and scheduler.\n",
            "03:38:19 ********** Completed epoch 9 **********\n",
            "03:38:19 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:38:19 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:38:20 Parameter Group `opt-1`: Starting epoch 10 with 50 steps and learning rate 1.00000E-05\n",
            "03:38:21 Evaluating model at test-frequency\n",
            "03:38:24 Obtained features, validation in progress\n",
            "03:38:24 Accuracy: 75.253%\n",
            "03:38:24 Micro F-score: 0.753\n",
            "03:38:24 Weighted F-score: 0.709\n",
            "03:38:24 Saving model at save-frequency, at epoch 9, step 0\n",
            "03:38:24 Saving model, optimizer, and scheduler.\n",
            "03:38:36 ********** Completed epoch 10 **********\n",
            "03:38:36 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:38:36 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:38:36 Final: Evaluating model at test-frequency\n",
            "03:38:38 Obtained features, validation in progress\n",
            "03:38:38 Accuracy: 76.768%\n",
            "03:38:38 Micro F-score: 0.768\n",
            "03:38:38 Weighted F-score: 0.727\n",
            "03:38:38 Final: Saving model at save-frequency\n",
            "03:38:38 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xORIYrVT5uyR",
        "outputId": "4e531182-1098-425f-b017-2c8911e17f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:39:17 Obtained features, validation in progress\n",
            "03:39:17 Accuracy: 76.768%\n",
            "03:39:17 Micro F-score: 0.768\n",
            "03:39:17 Weighted F-score: 0.727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3 Single classification (Vehicle Make)"
      ],
      "metadata": {
        "id": "eYZy0rOL65WQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = \"make\"   # Make sure to change this to whatever name you used for make in your `original_tool_images` crawler\n",
        "class_idx = 4         # Make sure to change this to whetever index `make` is in your Crawler's tuple!\n",
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "wlVSOq4b659w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZrzg_AF68QV",
        "outputId": "7460c0bd-c970-4fdb-9cd4-4775f95ab4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = \"./GLAMOR/profiles/CarZam/base_config.yml\", config_inject=[\n",
        "    (\"SAVE.MODEL_QUALIFIER\", class_name)\n",
        "])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ3h53yS6-Fl",
        "outputId": "4d1a97f8-9a5d-4ca7-9cec-21fb96f21e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Injected key-value pair:  SAVE.MODEL_QUALIFIER, make\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4PqBeis7BXw",
        "outputId": "a1af3ceb-5035-4765-97e8-7c3a4e9798c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:40:49 ****************************************\n",
            "03:40:49 \n",
            "03:40:49 \n",
            "03:40:49 Using the following configuration:\n",
            "03:40:49 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx: 4\n",
            "      classificationclass: make\n",
            "      pathidx: 0\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: ClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: ''\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: out1\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: classification_model_builder\n",
            "  MODEL_ARCH: ClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS: {}\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: singleclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: make\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "03:40:49 \n",
            "03:40:49 \n",
            "03:40:49 ****************************************\n",
            "03:40:49 No previous stop detected. Will start from epoch 0\n",
            "03:40:49 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "03:40:49 Reading data with DataReader DataReader\n",
            "03:40:49 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "03:40:49 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "03:40:49 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "03:40:49 Updating GENERATOR to queued class ClassificationGenerator\n",
            "03:40:49 Updating CRAWLER to CarZamCrawler\n",
            "03:40:49 Generated training data generator with 1575 training data points\n",
            "03:40:49 Running classification model with classes: {'make': {'classes': 36}}\n",
            "03:40:49 Generated test data/query generator\n",
            "03:40:49 Loaded classification_model_builder from ednaml.models to build model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers\n",
            "\n",
            "types: ['ElectricVehicle', 'Wagon', 'Coupe', 'SUV', 'Van', 'PickupTruck', 'Sedan', 'Hybrid', 'LuxuryVehicle', 'Convertible', 'Diesel', 'SportsCar', 'Crossover']\n",
            "Tuple_expanded\n",
            "\n",
            "[('unzipped/original_tool_images/Hybrid Silver 2021 Toyota Avalon Hybrid.jpg', 7, 2, 0, 7), ('unzipped/original_tool_images/Crossover Black 2018 Jeep Compass.jpg', 12, 3, 5, 27), ('unzipped/original_tool_images/Sedan Gray 2017 Honda Fit.jpg', 6, 0, 8, 10), ('unzipped/original_tool_images/Pickup Truck Tan 2017 Toyota Tacoma.jpg', 5, 7, 8, 7), ('unzipped/original_tool_images/Luxury Vehicle Gold 2015 Cadillac CTS.jpg', 8, 11, 1, 18)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:40:49 Finished instantiating model with ClassificationResnet architecture\n",
            "03:40:49 Adding plugins after constructing model\n",
            "03:40:49 No saved model weights provided.\n",
            "03:40:49 Model Summary retured the following error:\n",
            "03:40:49 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "03:40:49 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "03:40:49 Built optimizer\n",
            "03:40:49 Built scheduler\n",
            "03:40:49 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "03:40:49 Built loss function\n",
            "03:40:49 Built loss optimizer\n",
            "03:40:49 Built loss scheduler\n",
            "03:40:49 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "03:40:49 Loaded ClassificationTrainer from ednaml.trainer to build Trainer\n",
            "03:40:49 Saving model metadata\n",
            "03:40:49 Backing up metadata\n",
            "03:40:49 Finished metadata backup\n",
            "03:40:49 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSi-4dZ07CoA",
        "outputId": "1e54a3d6-a08a-4087-cc72-8ee5a217e4e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:40:58 Starting training\n",
            "03:40:58 Logging to:\torigtoolimgs-v1-singleclass-make-logger.log\n",
            "03:40:58 Models will be saved to local directory:\torigtoolimgs-v1-singleclass-make\n",
            "03:40:58 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "03:40:58 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "03:40:58 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "03:40:58 Performing initial evaluation...\n",
            "03:41:00 Obtained features, validation in progress\n",
            "03:41:00 Accuracy: 0.000%\n",
            "03:41:00 Micro F-score: 0.000\n",
            "03:41:00 Weighted F-score: 0.000\n",
            "03:41:00 Starting training from 0\n",
            "03:41:01 Parameter Group `opt-1`: Starting epoch 0 with 50 steps and learning rate 1.00000E-05\n",
            "03:41:17 ********** Completed epoch 0 **********\n",
            "03:41:17 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:41:17 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:41:18 Parameter Group `opt-1`: Starting epoch 1 with 50 steps and learning rate 1.00000E-05\n",
            "03:41:18 Evaluating model at test-frequency\n",
            "03:41:21 Obtained features, validation in progress\n",
            "03:41:21 Accuracy: 10.101%\n",
            "03:41:21 Micro F-score: 0.101\n",
            "03:41:21 Weighted F-score: 0.124\n",
            "03:41:21 Saving model at save-frequency, at epoch 0, step 0\n",
            "03:41:21 Saving model, optimizer, and scheduler.\n",
            "03:41:33 ********** Completed epoch 1 **********\n",
            "03:41:33 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:41:33 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:41:34 Parameter Group `opt-1`: Starting epoch 2 with 50 steps and learning rate 1.00000E-05\n",
            "03:41:35 Evaluating model at test-frequency\n",
            "03:41:37 Obtained features, validation in progress\n",
            "03:41:37 Accuracy: 20.707%\n",
            "03:41:37 Micro F-score: 0.207\n",
            "03:41:37 Weighted F-score: 0.215\n",
            "03:41:37 Saving model at save-frequency, at epoch 1, step 0\n",
            "03:41:37 Saving model, optimizer, and scheduler.\n",
            "03:41:50 ********** Completed epoch 2 **********\n",
            "03:41:50 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:41:50 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:41:50 Parameter Group `opt-1`: Starting epoch 3 with 50 steps and learning rate 1.00000E-05\n",
            "03:41:51 Evaluating model at test-frequency\n",
            "03:41:53 Obtained features, validation in progress\n",
            "03:41:53 Accuracy: 33.838%\n",
            "03:41:53 Micro F-score: 0.338\n",
            "03:41:53 Weighted F-score: 0.325\n",
            "03:41:53 Saving model at save-frequency, at epoch 2, step 0\n",
            "03:41:53 Saving model, optimizer, and scheduler.\n",
            "03:42:06 ********** Completed epoch 3 **********\n",
            "03:42:06 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:42:06 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:42:07 Parameter Group `opt-1`: Starting epoch 4 with 50 steps and learning rate 1.00000E-05\n",
            "03:42:08 Evaluating model at test-frequency\n",
            "03:42:10 Obtained features, validation in progress\n",
            "03:42:10 Accuracy: 41.919%\n",
            "03:42:10 Micro F-score: 0.419\n",
            "03:42:10 Weighted F-score: 0.401\n",
            "03:42:10 Saving model at save-frequency, at epoch 3, step 0\n",
            "03:42:10 Saving model, optimizer, and scheduler.\n",
            "03:42:23 ********** Completed epoch 4 **********\n",
            "03:42:23 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:42:23 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:42:23 Parameter Group `opt-1`: Starting epoch 5 with 50 steps and learning rate 1.00000E-05\n",
            "03:42:23 Evaluating model at test-frequency\n",
            "03:42:26 Obtained features, validation in progress\n",
            "03:42:26 Accuracy: 47.475%\n",
            "03:42:26 Micro F-score: 0.475\n",
            "03:42:26 Weighted F-score: 0.461\n",
            "03:42:26 Saving model at save-frequency, at epoch 4, step 0\n",
            "03:42:26 Saving model, optimizer, and scheduler.\n",
            "03:42:39 ********** Completed epoch 5 **********\n",
            "03:42:39 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:42:39 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:42:39 Parameter Group `opt-1`: Starting epoch 6 with 50 steps and learning rate 1.00000E-05\n",
            "03:42:40 Evaluating model at test-frequency\n",
            "03:42:43 Obtained features, validation in progress\n",
            "03:42:43 Accuracy: 49.495%\n",
            "03:42:43 Micro F-score: 0.495\n",
            "03:42:43 Weighted F-score: 0.468\n",
            "03:42:43 Saving model at save-frequency, at epoch 5, step 0\n",
            "03:42:43 Saving model, optimizer, and scheduler.\n",
            "03:42:55 ********** Completed epoch 6 **********\n",
            "03:42:55 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:42:55 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:42:55 Parameter Group `opt-1`: Starting epoch 7 with 50 steps and learning rate 1.00000E-05\n",
            "03:42:55 Evaluating model at test-frequency\n",
            "03:42:58 Obtained features, validation in progress\n",
            "03:42:58 Accuracy: 52.525%\n",
            "03:42:58 Micro F-score: 0.525\n",
            "03:42:58 Weighted F-score: 0.496\n",
            "03:42:58 Saving model at save-frequency, at epoch 6, step 0\n",
            "03:42:58 Saving model, optimizer, and scheduler.\n",
            "03:43:10 ********** Completed epoch 7 **********\n",
            "03:43:10 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:43:10 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:43:11 Parameter Group `opt-1`: Starting epoch 8 with 50 steps and learning rate 1.00000E-05\n",
            "03:43:12 Evaluating model at test-frequency\n",
            "03:43:15 Obtained features, validation in progress\n",
            "03:43:15 Accuracy: 53.535%\n",
            "03:43:15 Micro F-score: 0.535\n",
            "03:43:15 Weighted F-score: 0.501\n",
            "03:43:15 Saving model at save-frequency, at epoch 7, step 0\n",
            "03:43:15 Saving model, optimizer, and scheduler.\n",
            "03:43:27 ********** Completed epoch 8 **********\n",
            "03:43:27 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:43:27 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:43:27 Parameter Group `opt-1`: Starting epoch 9 with 50 steps and learning rate 1.00000E-05\n",
            "03:43:28 Evaluating model at test-frequency\n",
            "03:43:30 Obtained features, validation in progress\n",
            "03:43:30 Accuracy: 55.051%\n",
            "03:43:30 Micro F-score: 0.551\n",
            "03:43:30 Weighted F-score: 0.512\n",
            "03:43:30 Saving model at save-frequency, at epoch 8, step 0\n",
            "03:43:30 Saving model, optimizer, and scheduler.\n",
            "03:43:43 ********** Completed epoch 9 **********\n",
            "03:43:43 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:43:43 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:43:43 Parameter Group `opt-1`: Starting epoch 10 with 50 steps and learning rate 1.00000E-05\n",
            "03:43:44 Evaluating model at test-frequency\n",
            "03:43:47 Obtained features, validation in progress\n",
            "03:43:47 Accuracy: 53.535%\n",
            "03:43:47 Micro F-score: 0.535\n",
            "03:43:47 Weighted F-score: 0.493\n",
            "03:43:47 Saving model at save-frequency, at epoch 9, step 0\n",
            "03:43:47 Saving model, optimizer, and scheduler.\n",
            "03:43:58 ********** Completed epoch 10 **********\n",
            "03:43:58 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "03:43:58 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "03:43:58 Final: Evaluating model at test-frequency\n",
            "03:44:00 Obtained features, validation in progress\n",
            "03:44:00 Accuracy: 53.030%\n",
            "03:44:00 Micro F-score: 0.530\n",
            "03:44:00 Weighted F-score: 0.477\n",
            "03:44:00 Final: Saving model at save-frequency\n",
            "03:44:00 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc8U1Dr37zmu",
        "outputId": "adacd1a3-7090-4faf-ae34-3d5e0d73b796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "03:44:19 Obtained features, validation in progress\n",
            "03:44:19 Accuracy: 53.030%\n",
            "03:44:19 Micro F-score: 0.530\n",
            "03:44:19 Weighted F-score: 0.477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Multiclass classifiers**\n",
        "Multiclass classifiers try to classify multiple things at once, using the same features. Sometimes it works, if the features are colocated or have some overlap. Othertimes, it doesn't work very well. We can examine this in case of our small dataset first."
      ],
      "metadata": {
        "id": "Sgznu1Ciek-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 Multi-class classification (color-type)\n",
        "Now we will try a model that performs vehicle type AND vehicle color classification together. The config is already prepared for this in profiles/color_type.yml."
      ],
      "metadata": {
        "id": "RcETjh1hetf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "w_vHL2SAevsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3XK44mwfRkW",
        "outputId": "0de5b076-37c3-4978-de25-3368de55c579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = [\"./GLAMOR/profiles/CarZam/base_config.yml\",\"./GLAMOR/profiles/CarZam/color_type.yml\"])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "# We have already set these in config\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "#eml.addGeneratorClass(MultiClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "id": "sSzXoTgrfSs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Uu3oss5fsKf",
        "outputId": "63b48e99-3111-4cdb-c2d6-ddf6c9e8a343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:21:07 ****************************************\n",
            "06:21:07 \n",
            "06:21:07 \n",
            "06:21:07 Using the following configuration:\n",
            "06:21:07 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx:\n",
            "      - 2\n",
            "      - 1\n",
            "      classificationclass:\n",
            "      - color\n",
            "      - vtype\n",
            "      pathidx: 0\n",
            "    GENERATOR: MultiClassificationGenerator\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: MultiClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: color\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: colorloss\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: vtype\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: typeloss\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: multiclassification_model_builder\n",
            "  MODEL_ARCH: MultiClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS:\n",
            "    number_outputs: 2\n",
            "    outputs:\n",
            "    - dimensions: null\n",
            "      label: vtype\n",
            "      name: type\n",
            "    - dimensions: null\n",
            "      label: color\n",
            "      name: out2\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: multiclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: color-vtype\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "06:21:07 \n",
            "06:21:07 \n",
            "06:21:07 ****************************************\n",
            "06:21:07 Model weights file resnet18-5c106cde.pth does not exist. Downloading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46827520/46827520 bytes [████████████████████████████████████████████████████████████████████████████████████████████████████]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:21:07 No previous stop detected. Will start from epoch 0\n",
            "06:21:07 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "06:21:07 Reading data with DataReader DataReader\n",
            "06:21:07 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Download of resnet18-5c106cde.pth to https://download.pytorch.org/models/resnet18-5c106cde.pth completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:21:07 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "06:21:07 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "06:21:07 Updating GENERATOR using config specification to MultiClassificationGenerator\n",
            "06:21:07 Updating CRAWLER to CarZamCrawler\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers\n",
            "\n",
            "types: ['Convertible', 'PickupTruck', 'Hybrid', 'Van', 'ElectricVehicle', 'Diesel', 'Crossover', 'Wagon', 'LuxuryVehicle', 'Sedan', 'SportsCar', 'Coupe', 'SUV']\n",
            "Tuple_expanded\n",
            "\n",
            "[('unzipped/original_tool_images/Hybrid Silver 2021 Toyota Avalon Hybrid.jpg', 2, 0, 2, 22), ('unzipped/original_tool_images/Crossover Black 2018 Jeep Compass.jpg', 6, 5, 0, 8), ('unzipped/original_tool_images/Sedan Gray 2017 Honda Fit.jpg', 9, 12, 5, 33), ('unzipped/original_tool_images/Pickup Truck Tan 2017 Toyota Tacoma.jpg', 1, 9, 5, 22), ('unzipped/original_tool_images/Luxury Vehicle Gold 2015 Cadillac CTS.jpg', 8, 3, 1, 27)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:21:07 Generated training data generator with 1575 training data points\n",
            "06:21:07 Running classification model with classes: {'color': {'classes': 13}, 'vtype': {'classes': 13}}\n",
            "06:21:07 Generated test data/query generator\n",
            "06:21:07 Loaded multiclassification_model_builder from ednaml.models to build model\n",
            "06:21:08 Finished instantiating model with MultiClassificationResnet architecture\n",
            "06:21:08 Adding plugins after constructing model\n",
            "06:21:08 No saved model weights provided.\n",
            "06:21:12 Model Summary retured the following error:\n",
            "06:21:12 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "06:21:12 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "06:21:12 Built optimizer\n",
            "06:21:12 Built scheduler\n",
            "06:21:12 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "06:21:12 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "06:21:12 Built loss function\n",
            "06:21:12 Built loss optimizer\n",
            "06:21:12 Built loss scheduler\n",
            "06:21:12 Built loss scheduler\n",
            "06:21:12 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "06:21:12 Loaded MultiClassificationTrainer from ednaml.trainer to build Trainer\n",
            "06:21:12 Saving model metadata\n",
            "06:21:12 Backing up metadata\n",
            "06:21:12 Finished metadata backup\n",
            "06:21:12 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn8VALwVfwTG",
        "outputId": "1ee45662-8f29-4971-ab7d-875a90fec633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:21:19 Starting training\n",
            "06:21:19 Logging to:\torigtoolimgs-v1-multiclass-color-vtype-logger.log\n",
            "06:21:19 Models will be saved to local directory:\torigtoolimgs-v1-multiclass-color-vtype\n",
            "06:21:19 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "06:21:19 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "06:21:19 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "06:21:19 Performing initial evaluation...\n",
            "06:21:27 Obtained features, validation in progress\n",
            "06:21:27 Metrics\tcolorloss\ttypeloss\n",
            "06:21:27 Accuracy\tcolor: 0.182\tvtype: 0.086\n",
            "06:21:27 M F-Score\tcolor: 0.182\tvtype: 0.086\n",
            "06:21:27 W F-Score\tcolor: 0.108\tvtype: 0.028\n",
            "06:21:27 Starting training from 0\n",
            "06:21:28 Parameter Group `opt-1`: Starting epoch 0 with 50 steps and learning rate 1.00000E-05\n",
            "06:21:42 ********** Completed epoch 0 **********\n",
            "06:21:42 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:21:42 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:21:42 Parameter Group `opt-1`: Starting epoch 1 with 50 steps and learning rate 1.00000E-05\n",
            "06:21:42 Evaluating model at test-frequency\n",
            "06:21:45 Obtained features, validation in progress\n",
            "06:21:45 Metrics\tcolorloss\ttypeloss\n",
            "06:21:45 Accuracy\tcolor: 0.419\tvtype: 0.237\n",
            "06:21:45 M F-Score\tcolor: 0.419\tvtype: 0.237\n",
            "06:21:45 W F-Score\tcolor: 0.453\tvtype: 0.240\n",
            "06:21:45 Saving model at save-frequency, at epoch 0, step 0\n",
            "06:21:45 Saving model, optimizer, and scheduler.\n",
            "06:21:57 ********** Completed epoch 1 **********\n",
            "06:21:57 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:21:57 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:21:58 Parameter Group `opt-1`: Starting epoch 2 with 50 steps and learning rate 1.00000E-05\n",
            "06:21:58 Evaluating model at test-frequency\n",
            "06:22:01 Obtained features, validation in progress\n",
            "06:22:01 Metrics\tcolorloss\ttypeloss\n",
            "06:22:01 Accuracy\tcolor: 0.657\tvtype: 0.303\n",
            "06:22:01 M F-Score\tcolor: 0.657\tvtype: 0.303\n",
            "06:22:01 W F-Score\tcolor: 0.637\tvtype: 0.282\n",
            "06:22:01 Saving model at save-frequency, at epoch 1, step 0\n",
            "06:22:01 Saving model, optimizer, and scheduler.\n",
            "06:22:13 ********** Completed epoch 2 **********\n",
            "06:22:13 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:22:13 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:22:13 Parameter Group `opt-1`: Starting epoch 3 with 50 steps and learning rate 1.00000E-05\n",
            "06:22:14 Evaluating model at test-frequency\n",
            "06:22:16 Obtained features, validation in progress\n",
            "06:22:16 Metrics\tcolorloss\ttypeloss\n",
            "06:22:16 Accuracy\tcolor: 0.687\tvtype: 0.369\n",
            "06:22:16 M F-Score\tcolor: 0.687\tvtype: 0.369\n",
            "06:22:16 W F-Score\tcolor: 0.656\tvtype: 0.337\n",
            "06:22:16 Saving model at save-frequency, at epoch 2, step 0\n",
            "06:22:16 Saving model, optimizer, and scheduler.\n",
            "06:22:29 ********** Completed epoch 3 **********\n",
            "06:22:29 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:22:29 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:22:30 Parameter Group `opt-1`: Starting epoch 4 with 50 steps and learning rate 1.00000E-05\n",
            "06:22:30 Evaluating model at test-frequency\n",
            "06:22:33 Obtained features, validation in progress\n",
            "06:22:33 Metrics\tcolorloss\ttypeloss\n",
            "06:22:33 Accuracy\tcolor: 0.707\tvtype: 0.354\n",
            "06:22:33 M F-Score\tcolor: 0.707\tvtype: 0.354\n",
            "06:22:33 W F-Score\tcolor: 0.669\tvtype: 0.319\n",
            "06:22:33 Saving model at save-frequency, at epoch 3, step 0\n",
            "06:22:33 Saving model, optimizer, and scheduler.\n",
            "06:22:45 ********** Completed epoch 4 **********\n",
            "06:22:45 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:22:45 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:22:45 Parameter Group `opt-1`: Starting epoch 5 with 50 steps and learning rate 1.00000E-05\n",
            "06:22:46 Evaluating model at test-frequency\n",
            "06:22:48 Obtained features, validation in progress\n",
            "06:22:48 Metrics\tcolorloss\ttypeloss\n",
            "06:22:48 Accuracy\tcolor: 0.732\tvtype: 0.389\n",
            "06:22:48 M F-Score\tcolor: 0.732\tvtype: 0.389\n",
            "06:22:48 W F-Score\tcolor: 0.693\tvtype: 0.354\n",
            "06:22:48 Saving model at save-frequency, at epoch 4, step 0\n",
            "06:22:48 Saving model, optimizer, and scheduler.\n",
            "06:23:00 ********** Completed epoch 5 **********\n",
            "06:23:00 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:23:00 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:23:01 Parameter Group `opt-1`: Starting epoch 6 with 50 steps and learning rate 1.00000E-05\n",
            "06:23:02 Evaluating model at test-frequency\n",
            "06:23:04 Obtained features, validation in progress\n",
            "06:23:04 Metrics\tcolorloss\ttypeloss\n",
            "06:23:04 Accuracy\tcolor: 0.722\tvtype: 0.364\n",
            "06:23:04 M F-Score\tcolor: 0.722\tvtype: 0.364\n",
            "06:23:04 W F-Score\tcolor: 0.681\tvtype: 0.318\n",
            "06:23:04 Saving model at save-frequency, at epoch 5, step 0\n",
            "06:23:04 Saving model, optimizer, and scheduler.\n",
            "06:23:16 ********** Completed epoch 6 **********\n",
            "06:23:16 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:23:16 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:23:17 Parameter Group `opt-1`: Starting epoch 7 with 50 steps and learning rate 1.00000E-05\n",
            "06:23:17 Evaluating model at test-frequency\n",
            "06:23:19 Obtained features, validation in progress\n",
            "06:23:19 Metrics\tcolorloss\ttypeloss\n",
            "06:23:19 Accuracy\tcolor: 0.722\tvtype: 0.348\n",
            "06:23:19 M F-Score\tcolor: 0.722\tvtype: 0.348\n",
            "06:23:19 W F-Score\tcolor: 0.681\tvtype: 0.302\n",
            "06:23:19 Saving model at save-frequency, at epoch 6, step 0\n",
            "06:23:19 Saving model, optimizer, and scheduler.\n",
            "06:23:32 ********** Completed epoch 7 **********\n",
            "06:23:32 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:23:32 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:23:32 Parameter Group `opt-1`: Starting epoch 8 with 50 steps and learning rate 1.00000E-05\n",
            "06:23:33 Evaluating model at test-frequency\n",
            "06:23:36 Obtained features, validation in progress\n",
            "06:23:36 Metrics\tcolorloss\ttypeloss\n",
            "06:23:36 Accuracy\tcolor: 0.732\tvtype: 0.318\n",
            "06:23:36 M F-Score\tcolor: 0.732\tvtype: 0.318\n",
            "06:23:36 W F-Score\tcolor: 0.689\tvtype: 0.271\n",
            "06:23:36 Saving model at save-frequency, at epoch 7, step 0\n",
            "06:23:36 Saving model, optimizer, and scheduler.\n",
            "06:23:47 ********** Completed epoch 8 **********\n",
            "06:23:47 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:23:47 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:23:48 Parameter Group `opt-1`: Starting epoch 9 with 50 steps and learning rate 1.00000E-05\n",
            "06:23:48 Evaluating model at test-frequency\n",
            "06:23:51 Obtained features, validation in progress\n",
            "06:23:51 Metrics\tcolorloss\ttypeloss\n",
            "06:23:51 Accuracy\tcolor: 0.732\tvtype: 0.323\n",
            "06:23:51 M F-Score\tcolor: 0.732\tvtype: 0.323\n",
            "06:23:51 W F-Score\tcolor: 0.690\tvtype: 0.280\n",
            "06:23:51 Saving model at save-frequency, at epoch 8, step 0\n",
            "06:23:51 Saving model, optimizer, and scheduler.\n",
            "06:24:03 ********** Completed epoch 9 **********\n",
            "06:24:03 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:24:03 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:24:03 Parameter Group `opt-1`: Starting epoch 10 with 50 steps and learning rate 1.00000E-05\n",
            "06:24:04 Evaluating model at test-frequency\n",
            "06:24:07 Obtained features, validation in progress\n",
            "06:24:07 Metrics\tcolorloss\ttypeloss\n",
            "06:24:07 Accuracy\tcolor: 0.737\tvtype: 0.313\n",
            "06:24:07 M F-Score\tcolor: 0.737\tvtype: 0.313\n",
            "06:24:07 W F-Score\tcolor: 0.696\tvtype: 0.260\n",
            "06:24:07 Saving model at save-frequency, at epoch 9, step 0\n",
            "06:24:07 Saving model, optimizer, and scheduler.\n",
            "06:24:19 ********** Completed epoch 10 **********\n",
            "06:24:19 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:24:19 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:24:19 Final: Evaluating model at test-frequency\n",
            "06:24:20 Obtained features, validation in progress\n",
            "06:24:20 Metrics\tcolorloss\ttypeloss\n",
            "06:24:20 Accuracy\tcolor: 0.742\tvtype: 0.313\n",
            "06:24:20 M F-Score\tcolor: 0.742\tvtype: 0.313\n",
            "06:24:20 W F-Score\tcolor: 0.701\tvtype: 0.259\n",
            "06:24:20 Final: Saving model at save-frequency\n",
            "06:24:20 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M5BpL-RfwbO",
        "outputId": "05b85f91-3d7d-48eb-8ec9-6d36dbe7699e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:25:30 Obtained features, validation in progress\n",
            "06:25:30 Metrics\tcolorloss\ttypeloss\n",
            "06:25:30 Accuracy\tcolor: 0.742\tvtype: 0.313\n",
            "06:25:30 M F-Score\tcolor: 0.742\tvtype: 0.313\n",
            "06:25:30 W F-Score\tcolor: 0.701\tvtype: 0.259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.2 Multi-class classification (color-type-make)**\n",
        "Now we will try a model that performs vehicle type vehicle color, and vehicle make classification together. The config is already prepared for this in profiles/color_type_make.yml"
      ],
      "metadata": {
        "id": "nsQPkZZJh26l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "lRhLTBrJh5BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnUY_Fqnh72Q",
        "outputId": "f2247ddb-fe33-48d9-cf83-fbcec47108fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = [\"./GLAMOR/profiles/CarZam/base_config.yml\",\"./GLAMOR/profiles/CarZam/color_type_make.yml\"])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "# We have already set these in config\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "#eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "id": "lGKMuRJoh_RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqKWd_ThiBxj",
        "outputId": "27bf60e2-4fd5-4e3c-94a6-5b6179b76b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:31:14 ****************************************\n",
            "06:31:14 \n",
            "06:31:14 \n",
            "06:31:14 Using the following configuration:\n",
            "06:31:14 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx:\n",
            "      - 2\n",
            "      - 1\n",
            "      - 4\n",
            "      classificationclass:\n",
            "      - color\n",
            "      - vtype\n",
            "      - make\n",
            "      pathidx: 0\n",
            "    GENERATOR: MultiClassificationGenerator\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: MultiClassificationTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: color\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: colorloss\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: vtype\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: typeloss\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: make\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: makeloss\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: multiclassification_model_builder\n",
            "  MODEL_ARCH: MultiClassificationResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS:\n",
            "    number_outputs: 3\n",
            "    outputs:\n",
            "    - dimensions: null\n",
            "      label: vtype\n",
            "      name: type\n",
            "    - dimensions: null\n",
            "      label: color\n",
            "      name: out2\n",
            "    - dimensions: null\n",
            "      label: make\n",
            "      name: makeout\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: multiclass\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: color-vtype-make\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "06:31:14 \n",
            "06:31:14 \n",
            "06:31:14 ****************************************\n",
            "06:31:14 No previous stop detected. Will start from epoch 0\n",
            "06:31:14 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "06:31:14 Reading data with DataReader DataReader\n",
            "06:31:14 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "06:31:14 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "06:31:14 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "06:31:14 Updating GENERATOR using config specification to MultiClassificationGenerator\n",
            "06:31:14 Updating CRAWLER to CarZamCrawler\n",
            "06:31:14 Generated training data generator with 1575 training data points\n",
            "06:31:14 Running classification model with classes: {'color': {'classes': 13}, 'vtype': {'classes': 13}, 'make': {'classes': 36}}\n",
            "06:31:14 Generated test data/query generator\n",
            "06:31:14 Loaded multiclassification_model_builder from ednaml.models to build model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers\n",
            "\n",
            "types: ['Convertible', 'PickupTruck', 'Hybrid', 'Van', 'ElectricVehicle', 'Diesel', 'Crossover', 'Wagon', 'LuxuryVehicle', 'Sedan', 'SportsCar', 'Coupe', 'SUV']\n",
            "Tuple_expanded\n",
            "\n",
            "[('unzipped/original_tool_images/Hybrid Silver 2021 Toyota Avalon Hybrid.jpg', 2, 0, 2, 22), ('unzipped/original_tool_images/Crossover Black 2018 Jeep Compass.jpg', 6, 5, 0, 8), ('unzipped/original_tool_images/Sedan Gray 2017 Honda Fit.jpg', 9, 12, 5, 33), ('unzipped/original_tool_images/Pickup Truck Tan 2017 Toyota Tacoma.jpg', 1, 9, 5, 22), ('unzipped/original_tool_images/Luxury Vehicle Gold 2015 Cadillac CTS.jpg', 8, 3, 1, 27)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:31:14 Finished instantiating model with MultiClassificationResnet architecture\n",
            "06:31:14 Adding plugins after constructing model\n",
            "06:31:14 No saved model weights provided.\n",
            "06:31:14 Model Summary retured the following error:\n",
            "06:31:14 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "06:31:14 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "06:31:14 Built optimizer\n",
            "06:31:14 Built scheduler\n",
            "06:31:14 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "06:31:14 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "06:31:14 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "06:31:14 Built loss function\n",
            "06:31:14 Built loss optimizer\n",
            "06:31:14 Built loss scheduler\n",
            "06:31:14 Built loss scheduler\n",
            "06:31:14 Built loss scheduler\n",
            "06:31:14 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "06:31:14 Loaded MultiClassificationTrainer from ednaml.trainer to build Trainer\n",
            "06:31:14 Saving model metadata\n",
            "06:31:14 Backing up metadata\n",
            "06:31:14 Finished metadata backup\n",
            "06:31:14 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z89_rcPEiDAm",
        "outputId": "52cf71e5-eab9-4b50-d471-a2982d3c3004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:31:26 Starting training\n",
            "06:31:26 Logging to:\torigtoolimgs-v1-multiclass-color-vtype-make-logger.log\n",
            "06:31:26 Models will be saved to local directory:\torigtoolimgs-v1-multiclass-color-vtype-make\n",
            "06:31:26 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "06:31:26 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "06:31:26 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "06:31:26 Performing initial evaluation...\n",
            "06:31:28 Obtained features, validation in progress\n",
            "06:31:28 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:31:28 Accuracy\tcolor: 0.111\tvtype: 0.025\tmake: 0.005\n",
            "06:31:28 M F-Score\tcolor: 0.111\tvtype: 0.025\tmake: 0.005\n",
            "06:31:28 W F-Score\tcolor: 0.036\tvtype: 0.008\tmake: 0.001\n",
            "06:31:28 Starting training from 0\n",
            "06:31:29 Parameter Group `opt-1`: Starting epoch 0 with 50 steps and learning rate 1.00000E-05\n",
            "06:31:42 ********** Completed epoch 0 **********\n",
            "06:31:42 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:31:42 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:31:43 Parameter Group `opt-1`: Starting epoch 1 with 50 steps and learning rate 1.00000E-05\n",
            "06:31:43 Evaluating model at test-frequency\n",
            "06:31:46 Obtained features, validation in progress\n",
            "06:31:46 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:31:46 Accuracy\tcolor: 0.384\tvtype: 0.202\tmake: 0.061\n",
            "06:31:46 M F-Score\tcolor: 0.384\tvtype: 0.202\tmake: 0.061\n",
            "06:31:46 W F-Score\tcolor: 0.420\tvtype: 0.208\tmake: 0.082\n",
            "06:31:46 Saving model at save-frequency, at epoch 0, step 0\n",
            "06:31:46 Saving model, optimizer, and scheduler.\n",
            "06:32:00 ********** Completed epoch 1 **********\n",
            "06:32:00 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:32:00 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:32:01 Parameter Group `opt-1`: Starting epoch 2 with 50 steps and learning rate 1.00000E-05\n",
            "06:32:02 Evaluating model at test-frequency\n",
            "06:32:04 Obtained features, validation in progress\n",
            "06:32:04 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:32:04 Accuracy\tcolor: 0.586\tvtype: 0.288\tmake: 0.111\n",
            "06:32:04 M F-Score\tcolor: 0.586\tvtype: 0.288\tmake: 0.111\n",
            "06:32:04 W F-Score\tcolor: 0.581\tvtype: 0.268\tmake: 0.123\n",
            "06:32:04 Saving model at save-frequency, at epoch 1, step 0\n",
            "06:32:04 Saving model, optimizer, and scheduler.\n",
            "06:32:16 ********** Completed epoch 2 **********\n",
            "06:32:16 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:32:16 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:32:17 Parameter Group `opt-1`: Starting epoch 3 with 50 steps and learning rate 1.00000E-05\n",
            "06:32:17 Evaluating model at test-frequency\n",
            "06:32:20 Obtained features, validation in progress\n",
            "06:32:20 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:32:20 Accuracy\tcolor: 0.662\tvtype: 0.318\tmake: 0.182\n",
            "06:32:20 M F-Score\tcolor: 0.662\tvtype: 0.318\tmake: 0.182\n",
            "06:32:20 W F-Score\tcolor: 0.611\tvtype: 0.292\tmake: 0.191\n",
            "06:32:20 Saving model at save-frequency, at epoch 2, step 0\n",
            "06:32:20 Saving model, optimizer, and scheduler.\n",
            "06:32:32 ********** Completed epoch 3 **********\n",
            "06:32:32 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:32:32 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:32:33 Parameter Group `opt-1`: Starting epoch 4 with 50 steps and learning rate 1.00000E-05\n",
            "06:32:33 Evaluating model at test-frequency\n",
            "06:32:36 Obtained features, validation in progress\n",
            "06:32:36 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:32:36 Accuracy\tcolor: 0.687\tvtype: 0.359\tmake: 0.222\n",
            "06:32:36 M F-Score\tcolor: 0.687\tvtype: 0.359\tmake: 0.222\n",
            "06:32:36 W F-Score\tcolor: 0.635\tvtype: 0.316\tmake: 0.229\n",
            "06:32:36 Saving model at save-frequency, at epoch 3, step 0\n",
            "06:32:36 Saving model, optimizer, and scheduler.\n",
            "06:32:48 ********** Completed epoch 4 **********\n",
            "06:32:48 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:32:48 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:32:49 Parameter Group `opt-1`: Starting epoch 5 with 50 steps and learning rate 1.00000E-05\n",
            "06:32:49 Evaluating model at test-frequency\n",
            "06:32:51 Obtained features, validation in progress\n",
            "06:32:52 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:32:52 Accuracy\tcolor: 0.682\tvtype: 0.379\tmake: 0.258\n",
            "06:32:52 M F-Score\tcolor: 0.682\tvtype: 0.379\tmake: 0.258\n",
            "06:32:52 W F-Score\tcolor: 0.619\tvtype: 0.320\tmake: 0.253\n",
            "06:32:52 Saving model at save-frequency, at epoch 4, step 0\n",
            "06:32:52 Saving model, optimizer, and scheduler.\n",
            "06:33:04 ********** Completed epoch 5 **********\n",
            "06:33:04 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:33:04 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:33:05 Parameter Group `opt-1`: Starting epoch 6 with 50 steps and learning rate 1.00000E-05\n",
            "06:33:06 Evaluating model at test-frequency\n",
            "06:33:08 Obtained features, validation in progress\n",
            "06:33:08 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:33:08 Accuracy\tcolor: 0.707\tvtype: 0.374\tmake: 0.253\n",
            "06:33:08 M F-Score\tcolor: 0.707\tvtype: 0.374\tmake: 0.253\n",
            "06:33:08 W F-Score\tcolor: 0.650\tvtype: 0.313\tmake: 0.256\n",
            "06:33:08 Saving model at save-frequency, at epoch 5, step 0\n",
            "06:33:08 Saving model, optimizer, and scheduler.\n",
            "06:33:20 ********** Completed epoch 6 **********\n",
            "06:33:20 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:33:20 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:33:20 Parameter Group `opt-1`: Starting epoch 7 with 50 steps and learning rate 1.00000E-05\n",
            "06:33:21 Evaluating model at test-frequency\n",
            "06:33:23 Obtained features, validation in progress\n",
            "06:33:23 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:33:23 Accuracy\tcolor: 0.707\tvtype: 0.374\tmake: 0.247\n",
            "06:33:23 M F-Score\tcolor: 0.707\tvtype: 0.374\tmake: 0.247\n",
            "06:33:23 W F-Score\tcolor: 0.650\tvtype: 0.322\tmake: 0.252\n",
            "06:33:23 Saving model at save-frequency, at epoch 6, step 0\n",
            "06:33:23 Saving model, optimizer, and scheduler.\n",
            "06:33:36 ********** Completed epoch 7 **********\n",
            "06:33:36 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:33:36 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:33:36 Parameter Group `opt-1`: Starting epoch 8 with 50 steps and learning rate 1.00000E-05\n",
            "06:33:37 Evaluating model at test-frequency\n",
            "06:33:40 Obtained features, validation in progress\n",
            "06:33:40 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:33:40 Accuracy\tcolor: 0.702\tvtype: 0.374\tmake: 0.242\n",
            "06:33:40 M F-Score\tcolor: 0.702\tvtype: 0.374\tmake: 0.242\n",
            "06:33:40 W F-Score\tcolor: 0.647\tvtype: 0.323\tmake: 0.248\n",
            "06:33:40 Saving model at save-frequency, at epoch 7, step 0\n",
            "06:33:40 Saving model, optimizer, and scheduler.\n",
            "06:33:52 ********** Completed epoch 8 **********\n",
            "06:33:52 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:33:52 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:33:52 Parameter Group `opt-1`: Starting epoch 9 with 50 steps and learning rate 1.00000E-05\n",
            "06:33:52 Evaluating model at test-frequency\n",
            "06:33:55 Obtained features, validation in progress\n",
            "06:33:55 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:33:55 Accuracy\tcolor: 0.707\tvtype: 0.384\tmake: 0.237\n",
            "06:33:55 M F-Score\tcolor: 0.707\tvtype: 0.384\tmake: 0.237\n",
            "06:33:55 W F-Score\tcolor: 0.654\tvtype: 0.352\tmake: 0.244\n",
            "06:33:55 Saving model at save-frequency, at epoch 8, step 0\n",
            "06:33:55 Saving model, optimizer, and scheduler.\n",
            "06:34:07 ********** Completed epoch 9 **********\n",
            "06:34:07 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:34:07 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:34:08 Parameter Group `opt-1`: Starting epoch 10 with 50 steps and learning rate 1.00000E-05\n",
            "06:34:09 Evaluating model at test-frequency\n",
            "06:34:12 Obtained features, validation in progress\n",
            "06:34:12 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:34:12 Accuracy\tcolor: 0.717\tvtype: 0.374\tmake: 0.232\n",
            "06:34:12 M F-Score\tcolor: 0.717\tvtype: 0.374\tmake: 0.232\n",
            "06:34:12 W F-Score\tcolor: 0.666\tvtype: 0.342\tmake: 0.244\n",
            "06:34:12 Saving model at save-frequency, at epoch 9, step 0\n",
            "06:34:12 Saving model, optimizer, and scheduler.\n",
            "06:34:24 ********** Completed epoch 10 **********\n",
            "06:34:24 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:34:24 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:34:24 Final: Evaluating model at test-frequency\n",
            "06:34:25 Obtained features, validation in progress\n",
            "06:34:25 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:34:25 Accuracy\tcolor: 0.722\tvtype: 0.369\tmake: 0.217\n",
            "06:34:25 M F-Score\tcolor: 0.722\tvtype: 0.369\tmake: 0.217\n",
            "06:34:25 W F-Score\tcolor: 0.675\tvtype: 0.328\tmake: 0.223\n",
            "06:34:25 Final: Saving model at save-frequency\n",
            "06:34:25 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt53we9qiGH5",
        "outputId": "6dbc1bdb-2130-45d9-adce-008dc9a70d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:35:15 Obtained features, validation in progress\n",
            "06:35:15 Metrics\tcolorloss\ttypeloss\tmakeloss\n",
            "06:35:15 Accuracy\tcolor: 0.722\tvtype: 0.369\tmake: 0.217\n",
            "06:35:15 M F-Score\tcolor: 0.722\tvtype: 0.369\tmake: 0.217\n",
            "06:35:15 W F-Score\tcolor: 0.675\tvtype: 0.328\tmake: 0.223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Multibranch classification\n",
        "Now we will try a model that uses multiple branches, each branch for a specific label, for classification. Then we will fuse the branches to classify one more things. So total, three classifications from a single model."
      ],
      "metadata": {
        "id": "Z063BC9AjA30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.1 Vehicle color and type, fused to classify vehicle make\n",
        "Now we will try a model that performs vehicle type AND vehicle color classification together, using 2 different branches, and fuses the results together for make classification. The config is already prepared for this in profiles/multibranch-ctm.yml"
      ],
      "metadata": {
        "id": "qHIqYcqzjDmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_idx = 0          # Change this to whichever index in tuple has path\n",
        "crawler_args = {\"file_name\" : \"original_tool_image.zip\"}"
      ],
      "metadata": {
        "id": "qagmjPNSjNr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fKgsS9VjPvK",
        "outputId": "1922fb20-ad88-4bc9-da92-fa779fcb87cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ednaml.core import EdnaML\n",
        "from ednaml.generators import ClassificationGenerator\n",
        "\n",
        "eml = EdnaML(config = [\"./GLAMOR/profiles/CarZam/base_config.yml\",\"./GLAMOR/profiles/CarZam/multibranch-ctm.yml\"])\n",
        "\n",
        "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS = crawler_args\n",
        "eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"pathidx\"] = path_idx\n",
        "# We have already set these in config\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"annotationidx\"] = class_idx\n",
        "#eml.cfg.EXECUTION.DATAREADER.DATASET_ARGS[\"classificationclass\"] = class_name\n",
        "\n",
        "#eml.addGeneratorClass(ClassificationGenerator)\n",
        "eml.addCrawlerClass(CarZamCrawler)"
      ],
      "metadata": {
        "id": "_UlwBneHjSnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eml.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TseqEGncjUee",
        "outputId": "ff201394-9c07-4cca-8ace-e285a8b04e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:36:52 ****************************************\n",
            "06:36:52 \n",
            "06:36:52 \n",
            "06:36:52 Using the following configuration:\n",
            "06:36:52 DEPLOYMENT:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS: {}\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS: {}\n",
            "    GENERATOR: null\n",
            "    GENERATOR_ARGS: {}\n",
            "  DEPLOY: BaseDeploy\n",
            "  DEPLOYMENT_ARGS: {}\n",
            "  EPOCHS: 1\n",
            "  OUTPUT_ARGS: {}\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "EXECUTION:\n",
            "  DATAREADER:\n",
            "    CRAWLER_ARGS:\n",
            "      file_name: original_tool_image.zip\n",
            "    DATAREADER: DataReader\n",
            "    DATASET_ARGS:\n",
            "      annotationidx:\n",
            "      - 2\n",
            "      - 1\n",
            "      - 4\n",
            "      classificationclass:\n",
            "      - color\n",
            "      - vtype\n",
            "      - make\n",
            "      pathidx: 0\n",
            "    GENERATOR: MultiClassificationGenerator\n",
            "    GENERATOR_ARGS: {}\n",
            "  EPOCHS: 10\n",
            "  FP16: false\n",
            "  MODEL_SERVING: Unused\n",
            "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
            "  PLUGIN:\n",
            "    HOOKS: always\n",
            "    RESET: false\n",
            "  SKIPEVAL: false\n",
            "  TEST_FREQUENCY: 1\n",
            "  TRAINER: MultiBranchTrainer\n",
            "  TRAINER_ARGS:\n",
            "    accumulation_steps: 4\n",
            "LOGGING:\n",
            "  INPUT_SIZE: null\n",
            "  STEP_VERBOSE: 100\n",
            "LOSS:\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: color\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: color-fc\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: vtype\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: type-fc\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: make\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: fuse\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: make\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: colorbranch\n",
            "- KWARGS:\n",
            "  - {}\n",
            "  LABEL: make\n",
            "  LAMBDAS:\n",
            "  - 1.0\n",
            "  LOSSES:\n",
            "  - SoftmaxLogitsLoss\n",
            "  NAME: typebranch\n",
            "LOSS_OPTIMIZER:\n",
            "- BASE_LR: 0.001\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "LOSS_SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "MODEL:\n",
            "  BUILDER: multibranch_model_builder\n",
            "  MODEL_ARCH: MultiBranchResnet\n",
            "  MODEL_BASE: resnet18\n",
            "  MODEL_KWARGS:\n",
            "    branches:\n",
            "    - name: colorbranch\n",
            "      number_outputs: 1\n",
            "      outputs:\n",
            "      - dimensions: null\n",
            "        label: color\n",
            "        name: color-fc\n",
            "    - name: typebranch\n",
            "      number_outputs: 1\n",
            "      outputs:\n",
            "      - dimensions: null\n",
            "        label: vtype\n",
            "        name: type-fc\n",
            "    fuse: true\n",
            "    fuse_dimensions: null\n",
            "    fuse_label: make\n",
            "    fuse_name: fuse\n",
            "    fuse_outputs:\n",
            "    - colorbranch\n",
            "    - typebranch\n",
            "    number_branches: 2\n",
            "    shared_block: 2\n",
            "    soft_target_branch:\n",
            "    - colorbranch\n",
            "    - typebranch\n",
            "    soft_target_output_source: fuse\n",
            "    soft_targets: true\n",
            "  MODEL_NORMALIZATION: bn\n",
            "  PARAMETER_GROUPS:\n",
            "  - opt-1\n",
            "MODEL_PLUGIN: {}\n",
            "OPTIMIZER:\n",
            "- BASE_LR: 1.0e-05\n",
            "  LR_BIAS_FACTOR: 1.0\n",
            "  OPTIMIZER: Adam\n",
            "  OPTIMIZER_KWARGS: {}\n",
            "  OPTIMIZER_NAME: opt-1\n",
            "  WEIGHT_BIAS_FACTOR: 0.0005\n",
            "  WEIGHT_DECAY: 0.0005\n",
            "SAVE:\n",
            "  CHECKPOINT_DIRECTORY: checkpoint\n",
            "  DRIVE_BACKUP: false\n",
            "  LOG_BACKUP: false\n",
            "  MODEL_BACKBONE: multibranch\n",
            "  MODEL_CORE_NAME: origtoolimgs\n",
            "  MODEL_QUALIFIER: color-vtype-make\n",
            "  MODEL_VERSION: 1\n",
            "  SAVE_FREQUENCY: 1\n",
            "  STEP_SAVE_FREQUENCY: 0\n",
            "SCHEDULER:\n",
            "- LR_KWARGS:\n",
            "    gamma: 0.1\n",
            "    step_size: 20\n",
            "  LR_SCHEDULER: StepLR\n",
            "  SCHEDULER_NAME: opt-1\n",
            "STORAGE:\n",
            "  STORAGE_ARGS: {}\n",
            "  TYPE: BaseStorage\n",
            "  URL: ./\n",
            "TEST_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "TRAIN_TRANSFORMATION:\n",
            "  ARGS:\n",
            "    channels: 3\n",
            "    h_flip: 0.5\n",
            "    i_shape:\n",
            "    - 200\n",
            "    - 200\n",
            "    normalization_mean: 0.5\n",
            "    normalization_scale: 0.5\n",
            "    normalization_std: 0.5\n",
            "    random_erase: true\n",
            "    random_erase_value: 0.3\n",
            "    t_crop: true\n",
            "  BATCH_SIZE: 32\n",
            "  WORKERS: 2\n",
            "extensions:\n",
            "- EXECUTION\n",
            "- SAVE\n",
            "- STORAGE\n",
            "- TRANSFORMATION\n",
            "- MODEL\n",
            "- LOSS\n",
            "- OPTIMIZER\n",
            "- SCHEDULER\n",
            "- LOSS_OPTIMIZER\n",
            "- LOSS_SCHEDULER\n",
            "- LOGGING\n",
            "- DEPLOYMENT\n",
            "- MODEL_PLUGIN\n",
            "\n",
            "06:36:52 \n",
            "06:36:52 \n",
            "06:36:52 ****************************************\n",
            "06:36:52 No previous stop detected. Will start from epoch 0\n",
            "06:36:52 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "06:36:52 Reading data with DataReader DataReader\n",
            "06:36:52 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
            "06:36:52 Default DATASET is <class 'torch.utils.data.dataset.Dataset'>\n",
            "06:36:52 Default GENERATOR is <class 'ednaml.generators.ImageGenerator.ImageGenerator'>\n",
            "06:36:52 Updating GENERATOR using config specification to MultiClassificationGenerator\n",
            "06:36:52 Updating CRAWLER to CarZamCrawler\n",
            "06:36:52 Generated training data generator with 1575 training data points\n",
            "06:36:52 Running classification model with classes: {'color': {'classes': 13}, 'vtype': {'classes': 13}, 'make': {'classes': 36}}\n",
            "06:36:52 Generated test data/query generator\n",
            "06:36:52 Loaded multibranch_model_builder from ednaml.models to build model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outliers\n",
            "\n",
            "types: ['Convertible', 'PickupTruck', 'Hybrid', 'Van', 'ElectricVehicle', 'Diesel', 'Crossover', 'Wagon', 'LuxuryVehicle', 'Sedan', 'SportsCar', 'Coupe', 'SUV']\n",
            "Tuple_expanded\n",
            "\n",
            "[('unzipped/original_tool_images/Hybrid Silver 2021 Toyota Avalon Hybrid.jpg', 2, 0, 2, 22), ('unzipped/original_tool_images/Crossover Black 2018 Jeep Compass.jpg', 6, 5, 0, 8), ('unzipped/original_tool_images/Sedan Gray 2017 Honda Fit.jpg', 9, 12, 5, 33), ('unzipped/original_tool_images/Pickup Truck Tan 2017 Toyota Tacoma.jpg', 1, 9, 5, 22), ('unzipped/original_tool_images/Luxury Vehicle Gold 2015 Cadillac CTS.jpg', 8, 3, 1, 27)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:36:53 Finished instantiating model with MultiBranchResnet architecture\n",
            "06:36:53 Adding plugins after constructing model\n",
            "06:36:53 No saved model weights provided.\n",
            "06:36:53 Model Summary retured the following error:\n",
            "06:36:53 Traceback (most recent call last):\n",
            "  File \"/content/GLAMOR/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
            "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
            "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
            "\n",
            "06:36:53 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
            "06:36:53 Built optimizer\n",
            "06:36:53 Built scheduler\n",
            "06:36:53 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "06:36:53 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "06:36:53 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "06:36:53 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "06:36:53 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
            "06:36:53 Built loss function\n",
            "06:36:53 Built loss optimizer\n",
            "06:36:53 Built loss scheduler\n",
            "06:36:53 Built loss scheduler\n",
            "06:36:53 Built loss scheduler\n",
            "06:36:53 Built loss scheduler\n",
            "06:36:53 Built loss scheduler\n",
            "06:36:53 Loaded BaseStorage from ednaml.storage to build Storage\n",
            "06:36:53 Loaded MultiBranchTrainer from ednaml.trainer to build Trainer\n",
            "06:36:53 Saving model metadata\n",
            "06:36:53 Backing up metadata\n",
            "06:36:53 Finished metadata backup\n",
            "06:36:53 1 GPUs available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eml.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIG8GEkLjWdd",
        "outputId": "388310f8-8598-447d-9773-84cd6852f14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:37:05 Starting training\n",
            "06:37:05 Logging to:\torigtoolimgs-v1-multibranch-color-vtype-make-logger.log\n",
            "06:37:05 Models will be saved to local directory:\torigtoolimgs-v1-multibranch-color-vtype-make\n",
            "06:37:05 Models will be saved with base name:\torigtoolimgs-v1_epoch[].pth\n",
            "06:37:05 Optimizers will be saved with base name:\torigtoolimgs-v1_epoch[]_optimizer.pth\n",
            "06:37:05 Schedulers will be saved with base name:\torigtoolimgs-v1_epoch[]_scheduler.pth\n",
            "06:37:05 Performing initial evaluation...\n",
            "06:37:07 Obtained features, validation in progress\n",
            "06:37:07 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:37:07 Accuracy\tcolor-fc: 0.086\ttype-fc: 0.071\tfuse: 0.020\tcolorbranch: 0.005\ttypebranch: 0.040\n",
            "06:37:07 M F-Score\tcolor-fc: 0.086\ttype-fc: 0.071\tfuse: 0.020\tcolorbranch: 0.005\ttypebranch: 0.040\n",
            "06:37:07 W F-Score\tcolor-fc: 0.045\ttype-fc: 0.042\tfuse: 0.005\tcolorbranch: 0.006\ttypebranch: 0.013\n",
            "06:37:07 Starting training from 0\n",
            "06:37:07 Parameter Group `opt-1`: Starting epoch 0 with 50 steps and learning rate 1.00000E-05\n",
            "06:37:21 ********** Completed epoch 0 **********\n",
            "06:37:21 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:37:21 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:37:22 Parameter Group `opt-1`: Starting epoch 1 with 50 steps and learning rate 1.00000E-05\n",
            "06:37:22 Evaluating model at test-frequency\n",
            "06:37:25 Obtained features, validation in progress\n",
            "06:37:25 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:37:25 Accuracy\tcolor-fc: 0.384\ttype-fc: 0.136\tfuse: 0.106\tcolorbranch: 0.020\ttypebranch: 0.015\n",
            "06:37:25 M F-Score\tcolor-fc: 0.384\ttype-fc: 0.136\tfuse: 0.106\tcolorbranch: 0.020\ttypebranch: 0.015\n",
            "06:37:25 W F-Score\tcolor-fc: 0.428\ttype-fc: 0.145\tfuse: 0.104\tcolorbranch: 0.026\ttypebranch: 0.016\n",
            "06:37:25 Saving model at save-frequency, at epoch 0, step 0\n",
            "06:37:25 Saving model, optimizer, and scheduler.\n",
            "06:37:38 ********** Completed epoch 1 **********\n",
            "06:37:38 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:37:38 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:37:39 Parameter Group `opt-1`: Starting epoch 2 with 50 steps and learning rate 1.00000E-05\n",
            "06:37:40 Evaluating model at test-frequency\n",
            "06:37:42 Obtained features, validation in progress\n",
            "06:37:42 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:37:42 Accuracy\tcolor-fc: 0.616\ttype-fc: 0.273\tfuse: 0.177\tcolorbranch: 0.035\ttypebranch: 0.051\n",
            "06:37:42 M F-Score\tcolor-fc: 0.616\ttype-fc: 0.273\tfuse: 0.177\tcolorbranch: 0.035\ttypebranch: 0.051\n",
            "06:37:42 W F-Score\tcolor-fc: 0.591\ttype-fc: 0.264\tfuse: 0.177\tcolorbranch: 0.040\ttypebranch: 0.065\n",
            "06:37:42 Saving model at save-frequency, at epoch 1, step 0\n",
            "06:37:42 Saving model, optimizer, and scheduler.\n",
            "06:37:55 ********** Completed epoch 2 **********\n",
            "06:37:55 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:37:55 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:37:55 Parameter Group `opt-1`: Starting epoch 3 with 50 steps and learning rate 1.00000E-05\n",
            "06:37:56 Evaluating model at test-frequency\n",
            "06:37:58 Obtained features, validation in progress\n",
            "06:37:58 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:37:58 Accuracy\tcolor-fc: 0.662\ttype-fc: 0.318\tfuse: 0.232\tcolorbranch: 0.045\ttypebranch: 0.081\n",
            "06:37:58 M F-Score\tcolor-fc: 0.662\ttype-fc: 0.318\tfuse: 0.232\tcolorbranch: 0.045\ttypebranch: 0.081\n",
            "06:37:58 W F-Score\tcolor-fc: 0.629\ttype-fc: 0.283\tfuse: 0.227\tcolorbranch: 0.044\ttypebranch: 0.074\n",
            "06:37:58 Saving model at save-frequency, at epoch 2, step 0\n",
            "06:37:58 Saving model, optimizer, and scheduler.\n",
            "06:38:12 ********** Completed epoch 3 **********\n",
            "06:38:12 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:38:12 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:38:12 Parameter Group `opt-1`: Starting epoch 4 with 50 steps and learning rate 1.00000E-05\n",
            "06:38:13 Evaluating model at test-frequency\n",
            "06:38:16 Obtained features, validation in progress\n",
            "06:38:16 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:38:16 Accuracy\tcolor-fc: 0.687\ttype-fc: 0.354\tfuse: 0.273\tcolorbranch: 0.091\ttypebranch: 0.131\n",
            "06:38:16 M F-Score\tcolor-fc: 0.687\ttype-fc: 0.354\tfuse: 0.273\tcolorbranch: 0.091\ttypebranch: 0.131\n",
            "06:38:16 W F-Score\tcolor-fc: 0.650\ttype-fc: 0.295\tfuse: 0.261\tcolorbranch: 0.075\ttypebranch: 0.117\n",
            "06:38:16 Saving model at save-frequency, at epoch 3, step 0\n",
            "06:38:16 Saving model, optimizer, and scheduler.\n",
            "06:38:28 ********** Completed epoch 4 **********\n",
            "06:38:29 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:38:29 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:38:29 Parameter Group `opt-1`: Starting epoch 5 with 50 steps and learning rate 1.00000E-05\n",
            "06:38:29 Evaluating model at test-frequency\n",
            "06:38:32 Obtained features, validation in progress\n",
            "06:38:32 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:38:32 Accuracy\tcolor-fc: 0.702\ttype-fc: 0.394\tfuse: 0.283\tcolorbranch: 0.086\ttypebranch: 0.141\n",
            "06:38:32 M F-Score\tcolor-fc: 0.702\ttype-fc: 0.394\tfuse: 0.283\tcolorbranch: 0.086\ttypebranch: 0.141\n",
            "06:38:32 W F-Score\tcolor-fc: 0.662\ttype-fc: 0.327\tfuse: 0.260\tcolorbranch: 0.061\ttypebranch: 0.119\n",
            "06:38:32 Saving model at save-frequency, at epoch 4, step 0\n",
            "06:38:32 Saving model, optimizer, and scheduler.\n",
            "06:38:46 ********** Completed epoch 5 **********\n",
            "06:38:46 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:38:46 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:38:47 Parameter Group `opt-1`: Starting epoch 6 with 50 steps and learning rate 1.00000E-05\n",
            "06:38:47 Evaluating model at test-frequency\n",
            "06:38:50 Obtained features, validation in progress\n",
            "06:38:50 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:38:50 Accuracy\tcolor-fc: 0.717\ttype-fc: 0.389\tfuse: 0.273\tcolorbranch: 0.101\ttypebranch: 0.146\n",
            "06:38:50 M F-Score\tcolor-fc: 0.717\ttype-fc: 0.389\tfuse: 0.273\tcolorbranch: 0.101\ttypebranch: 0.146\n",
            "06:38:50 W F-Score\tcolor-fc: 0.670\ttype-fc: 0.319\tfuse: 0.252\tcolorbranch: 0.070\ttypebranch: 0.122\n",
            "06:38:50 Saving model at save-frequency, at epoch 5, step 0\n",
            "06:38:50 Saving model, optimizer, and scheduler.\n",
            "06:39:03 ********** Completed epoch 6 **********\n",
            "06:39:03 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:39:03 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:39:03 Parameter Group `opt-1`: Starting epoch 7 with 50 steps and learning rate 1.00000E-05\n",
            "06:39:04 Evaluating model at test-frequency\n",
            "06:39:06 Obtained features, validation in progress\n",
            "06:39:06 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:39:06 Accuracy\tcolor-fc: 0.712\ttype-fc: 0.359\tfuse: 0.278\tcolorbranch: 0.096\ttypebranch: 0.136\n",
            "06:39:06 M F-Score\tcolor-fc: 0.712\ttype-fc: 0.359\tfuse: 0.278\tcolorbranch: 0.096\ttypebranch: 0.136\n",
            "06:39:06 W F-Score\tcolor-fc: 0.662\ttype-fc: 0.288\tfuse: 0.242\tcolorbranch: 0.060\ttypebranch: 0.112\n",
            "06:39:06 Saving model at save-frequency, at epoch 6, step 0\n",
            "06:39:06 Saving model, optimizer, and scheduler.\n",
            "06:39:20 ********** Completed epoch 7 **********\n",
            "06:39:20 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:39:20 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:39:20 Parameter Group `opt-1`: Starting epoch 8 with 50 steps and learning rate 1.00000E-05\n",
            "06:39:21 Evaluating model at test-frequency\n",
            "06:39:24 Obtained features, validation in progress\n",
            "06:39:24 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:39:24 Accuracy\tcolor-fc: 0.737\ttype-fc: 0.369\tfuse: 0.258\tcolorbranch: 0.111\ttypebranch: 0.152\n",
            "06:39:24 M F-Score\tcolor-fc: 0.737\ttype-fc: 0.369\tfuse: 0.258\tcolorbranch: 0.111\ttypebranch: 0.152\n",
            "06:39:24 W F-Score\tcolor-fc: 0.688\ttype-fc: 0.292\tfuse: 0.220\tcolorbranch: 0.069\ttypebranch: 0.129\n",
            "06:39:24 Saving model at save-frequency, at epoch 7, step 0\n",
            "06:39:24 Saving model, optimizer, and scheduler.\n",
            "06:39:36 ********** Completed epoch 8 **********\n",
            "06:39:36 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:39:36 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:39:37 Parameter Group `opt-1`: Starting epoch 9 with 50 steps and learning rate 1.00000E-05\n",
            "06:39:37 Evaluating model at test-frequency\n",
            "06:39:40 Obtained features, validation in progress\n",
            "06:39:40 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:39:40 Accuracy\tcolor-fc: 0.722\ttype-fc: 0.389\tfuse: 0.247\tcolorbranch: 0.106\ttypebranch: 0.157\n",
            "06:39:40 M F-Score\tcolor-fc: 0.722\ttype-fc: 0.389\tfuse: 0.247\tcolorbranch: 0.106\ttypebranch: 0.157\n",
            "06:39:40 W F-Score\tcolor-fc: 0.672\ttype-fc: 0.319\tfuse: 0.203\tcolorbranch: 0.063\ttypebranch: 0.133\n",
            "06:39:40 Saving model at save-frequency, at epoch 8, step 0\n",
            "06:39:40 Saving model, optimizer, and scheduler.\n",
            "06:39:53 ********** Completed epoch 9 **********\n",
            "06:39:53 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:39:53 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:39:54 Parameter Group `opt-1`: Starting epoch 10 with 50 steps and learning rate 1.00000E-05\n",
            "06:39:55 Evaluating model at test-frequency\n",
            "06:39:57 Obtained features, validation in progress\n",
            "06:39:57 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:39:57 Accuracy\tcolor-fc: 0.737\ttype-fc: 0.379\tfuse: 0.242\tcolorbranch: 0.101\ttypebranch: 0.157\n",
            "06:39:57 M F-Score\tcolor-fc: 0.737\ttype-fc: 0.379\tfuse: 0.242\tcolorbranch: 0.101\ttypebranch: 0.157\n",
            "06:39:57 W F-Score\tcolor-fc: 0.695\ttype-fc: 0.300\tfuse: 0.201\tcolorbranch: 0.063\ttypebranch: 0.125\n",
            "06:39:57 Saving model at save-frequency, at epoch 9, step 0\n",
            "06:39:57 Saving model, optimizer, and scheduler.\n",
            "06:40:10 ********** Completed epoch 10 **********\n",
            "06:40:10 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
            "06:40:10 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
            "06:40:10 Final: Evaluating model at test-frequency\n",
            "06:40:12 Obtained features, validation in progress\n",
            "06:40:12 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:40:12 Accuracy\tcolor-fc: 0.707\ttype-fc: 0.379\tfuse: 0.232\tcolorbranch: 0.106\ttypebranch: 0.152\n",
            "06:40:12 M F-Score\tcolor-fc: 0.707\ttype-fc: 0.379\tfuse: 0.232\tcolorbranch: 0.106\ttypebranch: 0.152\n",
            "06:40:12 W F-Score\tcolor-fc: 0.650\ttype-fc: 0.295\tfuse: 0.192\tcolorbranch: 0.065\ttypebranch: 0.120\n",
            "06:40:12 Final: Saving model at save-frequency\n",
            "06:40:12 Saving model, optimizer, and scheduler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp = eml.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avBKqLsjjYr5",
        "outputId": "eb3f89c2-fe8d-4b28-8ff1-e2654cbc961a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06:40:56 Obtained features, validation in progress\n",
            "06:40:56 Metrics\tcolor-fc\ttype-fc\tfuse\tcolorbranch\ttypebranch\n",
            "06:40:56 Accuracy\tcolor-fc: 0.707\ttype-fc: 0.379\tfuse: 0.232\tcolorbranch: 0.106\ttypebranch: 0.152\n",
            "06:40:56 M F-Score\tcolor-fc: 0.707\ttype-fc: 0.379\tfuse: 0.232\tcolorbranch: 0.106\ttypebranch: 0.152\n",
            "06:40:56 W F-Score\tcolor-fc: 0.650\ttype-fc: 0.295\tfuse: 0.192\tcolorbranch: 0.065\ttypebranch: 0.120\n"
          ]
        }
      ]
    }
  ]
}